{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8c33de",
   "metadata": {},
   "source": [
    "# Entregable 2: Comparación de distintos espacios de color en imágenes digitales\n",
    "\n",
    "Este proyecto presenta un análisis completo de diferentes espacios de color y sus aplicaciones prácticas en visión por ordenador.\n",
    "\n",
    "## Creación de imágenes de Prueba\n",
    "Las imágenes utilizadas en los experimentos se gestionan automáticamente:\n",
    "- **Primera ejecución**: Se crean y guardan en la carpeta `data/`\n",
    "- **Ejecuciones posteriores**: Se cargan desde `data/`\n",
    "- **Imágenes incluidas**: \n",
    "  - `gradiente_rgb.png` - Gradientes de colores primarios\n",
    "  - `colores_saturados.png` - Colores puros\n",
    "  - `espectro_hsv.png` - Espectro completo HSV (Hue horizontal, Saturación vertical)\n",
    "  - `codigo_barras.png` - Patrón binario para análisis en escala de grises\n",
    "  - `tonos_piel.png` - Tonos de piel para detección YCrCb\n",
    "  - `formas_geometricas.png` - Formas variadas para detección de bordes\n",
    "\n",
    "## Espacios de Color a Analizar\n",
    "1. **RGB**\n",
    "2. **HSV**   \n",
    "3. **CIELAB (Lab)** \n",
    "4. **YCrCb**\n",
    "5. **Escala de Grises** \n",
    "6. **XYZ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88475a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26329391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestión de imágenes de prueba - Creación y carga desde data/\n",
    "\n",
    "def crear_imagen_gradiente_rgb():\n",
    "    \"\"\"Crea una imagen con gradientes de colores RGB\"\"\"\n",
    "    altura, ancho = 300, 400\n",
    "    imagen = np.zeros((altura, ancho, 3), dtype=np.uint8)\n",
    "    #Las imágenes en OpenCV usan el formato BGR en lugar de RGB\n",
    "\n",
    "        # Gradiente horizontal de rojo\n",
    "    for x in range(ancho//3):\n",
    "        imagen[:300, x] = [0, 0, int(255 * x / (ancho//3))]\n",
    "\n",
    "    # Gradiente horizontal de verde\n",
    "    for x in range(ancho//3, 2*ancho//3):\n",
    "        imagen[:300, x] = [0, int(255 * (x - ancho//3) / (ancho//3)), 0]\n",
    "\n",
    "    # Gradiente horizontal de azul\n",
    "    for x in range(2*ancho//3, ancho):\n",
    "        imagen[:300, x] = [int(255 * (x - 2*ancho//3) / (ancho//3)), 0, 0]\n",
    "\n",
    "    return imagen\n",
    "\n",
    "def crear_imagen_colores_saturados():\n",
    "    \"\"\"Crea una imagen con colores saturados para análisis HSV\"\"\"\n",
    "    altura, ancho = 300, 400\n",
    "    imagen = np.zeros((altura, ancho, 3), dtype=np.uint8)\n",
    "    \n",
    "     # Colores en formato BGR (Blue, Green, Red)\n",
    "    colores = [\n",
    "        [0, 0, 255],      # Rojo en BGR\n",
    "        [0, 255, 255],    # Amarillo en BGR  \n",
    "        [0, 255, 0],      # Verde en BGR\n",
    "        [255, 255, 0],    # Cian en BGR\n",
    "        [255, 0, 0],      # Azul en BGR\n",
    "        [255, 0, 255]     # Magenta en BGR\n",
    "    ]\n",
    "    \n",
    "    ancho_banda = ancho // len(colores)\n",
    "    for i, color in enumerate(colores):\n",
    "        x_inicio = i * ancho_banda\n",
    "        x_fin = min((i + 1) * ancho_banda, ancho)\n",
    "        imagen[:, x_inicio:x_fin] = color\n",
    "    \n",
    "    return imagen\n",
    "\n",
    "def crear_codigo_barras():\n",
    "    \"\"\"Crea una imagen de código de barras\"\"\"\n",
    "    altura, ancho = 200, 400\n",
    "    imagen = np.ones((altura, ancho), dtype=np.uint8) * 255\n",
    "    \n",
    "    # Patrón de barras\n",
    "    patron = [3, 1, 2, 1, 3, 2, 1, 3, 1, 2, 3, 1, 2, 1, 3]\n",
    "    x = 50\n",
    "    color_actual = 0  # 0 para negro, 255 para blanco\n",
    "    \n",
    "    for ancho_barra in patron:\n",
    "        imagen[:, x:x+ancho_barra*8] = color_actual\n",
    "        color_actual = 255 - color_actual  # Alternar entre negro y blanco\n",
    "        x += ancho_barra * 8\n",
    "    \n",
    "    return imagen\n",
    "\n",
    "def crear_imagen_espectro_hsv():\n",
    "    altura, ancho = 300, 400\n",
    "    imagen = np.zeros((altura, ancho, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Crear espectro HSV completo con variación en los tres canales\n",
    "    for y in range(altura):\n",
    "        for x in range(ancho):\n",
    "            # Calcular valores HSV\n",
    "            # Hue: varía horizontalmente de 0 a 179 (rango OpenCV)\n",
    "            h = int((x / ancho) * 179)\n",
    "            \n",
    "            # Saturation: varía verticalmente de 255 (arriba) a 0 (abajo)\n",
    "            s = int(255 * (1 - y / altura))\n",
    "            \n",
    "            # Esquina superior izquierda: V máximo (255)\n",
    "            # Esquina inferior derecha: V mínimo (pero no negro total)\n",
    "            factor_diagonal = (x / ancho + (1 - y / altura)) / 2\n",
    "            v = int(100 + 155 * factor_diagonal)  # Rango: 100-255 para mantener visibilidad\n",
    "            \n",
    "            # Crear pixel HSV y convertir a BGR\n",
    "            hsv_pixel = np.array([[[h, s, v]]], dtype=np.uint8)\n",
    "            bgr_pixel = cv2.cvtColor(hsv_pixel, cv2.COLOR_HSV2BGR)\n",
    "            imagen[y, x] = bgr_pixel[0, 0]\n",
    "    \n",
    "    return imagen\n",
    "\n",
    "def crear_imagen_con_piel():\n",
    "    \"\"\"Crea una imagen con tonos de piel y colores puros\"\"\"\n",
    "    altura, ancho = 300, 400\n",
    "    imagen = np.zeros((altura, ancho, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Definir tonos de piel extremos para el gradiente (valores BGR)\n",
    "    piel_clara = np.array([180, 200, 240], dtype=np.float32)    # Piel muy clara (rosada)\n",
    "    piel_oscura = np.array([35, 60, 85], dtype=np.float32)     # Piel muy oscura\n",
    "    \n",
    "    # Crear gradiente horizontal de tonos de piel\n",
    "    for x in range(ancho):\n",
    "        # Calcular factor de interpolación (0.0 a 1.0)\n",
    "        factor = x / (ancho - 1)\n",
    "        \n",
    "        # Interpolar entre piel clara y oscura\n",
    "        color_piel = piel_clara * (1 - factor) + piel_oscura * factor\n",
    "        \n",
    "        # Asignar color a la mitad superior de la imagen\n",
    "        imagen[:altura//2, x] = color_piel.astype(np.uint8)\n",
    "    \n",
    "    # Añadir otros colores para comparación (parte inferior)\n",
    "    otros_colores = [\n",
    "        [0, 0, 255],        # Rojo\n",
    "        [0, 255, 0],        # Verde  \n",
    "        [255, 0, 0],        # Azul\n",
    "        [255, 255, 255],    # Blanco\n",
    "        [128, 128, 128],    # Gris\n",
    "        [0, 255, 255],      # Amarillo\n",
    "    ]\n",
    "    \n",
    "    seccion_ancho = ancho // len(otros_colores)\n",
    "    \n",
    "    # Añadir otros colores en la parte inferior\n",
    "    for i, color in enumerate(otros_colores):\n",
    "        x_inicio = i * seccion_ancho\n",
    "        x_fin = min((i + 1) * seccion_ancho, ancho)\n",
    "        imagen[altura//2:, x_inicio:x_fin] = color\n",
    "    \n",
    "    return imagen\n",
    "\n",
    "# Añadir esta función después de crear_imagen_con_piel()\n",
    "\n",
    "def crear_imagen_formas_geometricas():\n",
    "    \"\"\"Crea una imagen con formas geométricas variadas para detección de bordes\"\"\"\n",
    "    altura, ancho = 400, 500\n",
    "    imagen = np.ones((altura, ancho, 3), dtype=np.uint8) * 255  # Fondo blanco\n",
    "    \n",
    "    # Colores variados en formato BGR\n",
    "    colores = [\n",
    "        [0, 0, 200],      # Rojo oscuro\n",
    "        [0, 150, 0],      # Verde oscuro  \n",
    "        [200, 0, 0],      # Azul oscuro\n",
    "        [0, 165, 255],    # Naranja\n",
    "        [128, 0, 128],    # Púrpura\n",
    "        [0, 255, 255],    # Amarillo\n",
    "        [255, 105, 180],  # Rosa\n",
    "        [50, 50, 50],     # Gris oscuro\n",
    "    ]\n",
    "    \n",
    "    # Círculos de diferentes tamaños\n",
    "    cv2.circle(imagen, (100, 100), 40, colores[0], -1)  # Círculo rojo sólido\n",
    "    cv2.circle(imagen, (250, 80), 35, colores[1], 3)    # Círculo verde hueco\n",
    "    cv2.circle(imagen, (400, 120), 50, colores[2], -1)  # Círculo azul sólido\n",
    "    \n",
    "    # Rectángulos y cuadrados\n",
    "    cv2.rectangle(imagen, (50, 200), (150, 280), colores[3], -1)    # Rectángulo naranja sólido\n",
    "    cv2.rectangle(imagen, (200, 180), (280, 260), colores[4], 5)    # Cuadrado púrpura hueco\n",
    "    cv2.rectangle(imagen, (350, 200), (450, 250), colores[5], -1)   # Rectángulo amarillo sólido\n",
    "    \n",
    "    # Triángulos usando polígonos\n",
    "    triangulo1 = np.array([[100, 320], [150, 380], [50, 380]], np.int32)\n",
    "    cv2.fillPoly(imagen, [triangulo1], colores[6])  # Triángulo rosa sólido\n",
    "    \n",
    "    triangulo2 = np.array([[300, 300], [350, 350], [250, 350]], np.int32)\n",
    "    cv2.polylines(imagen, [triangulo2], True, colores[7], 4)  # Triángulo gris hueco\n",
    "    \n",
    "    # Formas más complejas\n",
    "    # Hexágono\n",
    "    hex_center = (400, 350)\n",
    "    hex_radius = 30\n",
    "    hex_points = []\n",
    "    for i in range(6):\n",
    "        angle = i * np.pi / 3\n",
    "        x = int(hex_center[0] + hex_radius * np.cos(angle))\n",
    "        y = int(hex_center[1] + hex_radius * np.sin(angle))\n",
    "        hex_points.append([x, y])\n",
    "    hex_points = np.array(hex_points, np.int32)\n",
    "    cv2.fillPoly(imagen, [hex_points], colores[1])  # Hexágono verde\n",
    "    \n",
    "    # Elipse\n",
    "    cv2.ellipse(imagen, (150, 350), (60, 30), 45, 0, 360, colores[0], -1)  # Elipse roja\n",
    "    \n",
    "    # Líneas y formas lineales\n",
    "    cv2.line(imagen, (20, 20), (480, 40), colores[7], 3)           # Línea diagonal\n",
    "    cv2.line(imagen, (20, 380), (480, 380), colores[2], 2)         # Línea horizontal\n",
    "    \n",
    "    # Agregar algo de texto para hacer más interesante la detección\n",
    "    cv2.putText(imagen, 'FORMAS', (200, 30), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                1, colores[7], 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Añadir algunos patrones de puntos\n",
    "    for i in range(5):\n",
    "        for j in range(3):\n",
    "            cv2.circle(imagen, (300 + i*15, 120 + j*15), 3, colores[4], -1)\n",
    "    \n",
    "    return imagen\n",
    "\n",
    "def cargar_o_crear_imagenes():\n",
    "    \"\"\"Carga las imágenes desde data/ o las crea si no existen\"\"\"\n",
    "    # Crear directorio data si no existe\n",
    "    data_dir = 'data'\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "        print(f\"Directorio '{data_dir}' creado\")\n",
    "    \n",
    "    # Rutas de las imágenes\n",
    "    rutas = {\n",
    "        'gradiente': os.path.join(data_dir, 'gradiente_rgb.png'),\n",
    "        'colores': os.path.join(data_dir, 'colores_saturados.png'),\n",
    "        'espectro_hsv': os.path.join(data_dir, 'espectro_hsv.png'),\n",
    "        'barras': os.path.join(data_dir, 'codigo_barras.png'),\n",
    "        'piel': os.path.join(data_dir, 'tonos_piel.png'),\n",
    "        'formas': os.path.join(data_dir, 'formas_geometricas.png')\n",
    "    }\n",
    "    \n",
    "    imagenes = {}\n",
    "    \n",
    "    # Cargar o crear cada imagen\n",
    "    for nombre, ruta in rutas.items():\n",
    "        if os.path.exists(ruta):\n",
    "            if nombre == 'barras':\n",
    "                # Código de barras es escala de grises\n",
    "                imagenes[nombre] = cv2.imread(ruta, cv2.IMREAD_GRAYSCALE)\n",
    "            else:\n",
    "                # Imágenes en color\n",
    "                imagenes[nombre] = cv2.imread(ruta)\n",
    "            print(f\"✓ Cargada imagen existente: {nombre}\")\n",
    "        else:\n",
    "            # Crear imagen sintética\n",
    "            if nombre == 'gradiente':\n",
    "                imagenes[nombre] = crear_imagen_gradiente_rgb()\n",
    "            elif nombre == 'colores':\n",
    "                imagenes[nombre] = crear_imagen_colores_saturados()\n",
    "            elif nombre == 'espectro_hsv':\n",
    "                imagenes[nombre] = crear_imagen_espectro_hsv()\n",
    "            elif nombre == 'barras':\n",
    "                imagenes[nombre] = crear_codigo_barras()\n",
    "            elif nombre == 'piel':\n",
    "                imagenes[nombre] = crear_imagen_con_piel()\n",
    "            elif nombre == 'formas': \n",
    "                imagenes[nombre] = crear_imagen_formas_geometricas()\n",
    "            \n",
    "            # Guardar imagen\n",
    "            cv2.imwrite(ruta, imagenes[nombre])\n",
    "            print(f\"✓ Creada y guardada nueva imagen: {nombre}\")\n",
    "\n",
    "    return imagenes['gradiente'], imagenes['colores'], imagenes['espectro_hsv'], imagenes['barras'], imagenes['piel'], imagenes['formas']\n",
    "\n",
    "# Cargar o crear las imágenes de prueba\n",
    "img_gradiente, img_colores, img_espectro_hsv, img_barras, img_piel, img_formas = cargar_o_crear_imagenes()\n",
    "\n",
    "# Mostrar las imágenes cargadas/creadas\n",
    "fig, axes = plt.subplots(2, 3, figsize=(25, 10))\n",
    "\n",
    "axes[0, 0].imshow(cv2.cvtColor(img_gradiente, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 0].set_title('Gradientes RGB')\n",
    "axes[0, 0].axis('off')\n",
    "\n",
    "axes[0, 1].imshow(cv2.cvtColor(img_colores, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title('Colores Saturados')\n",
    "axes[0, 1].axis('off')\n",
    "\n",
    "axes[0, 2].imshow(cv2.cvtColor(img_espectro_hsv, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 2].set_title('Espectro HSV Completo')\n",
    "axes[0, 2].axis('off')\n",
    "\n",
    "axes[1, 0].imshow(img_barras, cmap='gray')\n",
    "axes[1, 0].set_title('Código de Barras')\n",
    "axes[1, 0].axis('off')\n",
    "\n",
    "axes[1, 1].imshow(cv2.cvtColor(img_piel, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title('Tonos de Piel')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "axes[1, 2].imshow(cv2.cvtColor(img_formas, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 2].set_title('Formas Geométricas')\n",
    "axes[1, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Sistema de gestión de imágenes configurado\")\n",
    "print(\"Las imágenes se guardan en 'data/' y se reutilizan en ejecuciones futuras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad6875",
   "metadata": {},
   "source": [
    "## 1. Espacio de Color RGB (Red, Green, Blue)\n",
    "\n",
    "### Características\n",
    "- Los colores se forman sumando intensidades de rojo, verde y azul\n",
    "- Cada canal tiene valores de 0-255 (8 bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d369948",
   "metadata": {},
   "source": [
    "### Experimento 1: Separación y Visualización de Canales RGB\n",
    "\n",
    "Utilizamos la imagen de **gradientes RGB** porque:\n",
    "- Cada sección contiene principalmente un color primario (rojo, verde, azul)\n",
    "- Los gradientes muestran cómo cambia la intensidad de cada canal de 0 a 255\n",
    "\n",
    "Separaremos los canales R, G, B de la imagen y los visualizaremos tanto en escala de grises (para ver la contribución individual) como en color (para ver el efecto visual de cada canal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f14e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 1: Separación y Visualización de Canales RGB\n",
    "r,g,b = cv2.split(cv2.cvtColor(img_gradiente, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Visualizar análisis RGB - Separación de canales\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 10))\n",
    "\n",
    "# Imagen original\n",
    "axes[0,0].imshow(cv2.cvtColor(img_gradiente, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Imagen Original')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "# Canales individuales en escala de grises\n",
    "axes[0,1].imshow(r, cmap='Greys')\n",
    "axes[0,1].set_title('Canal Rojo')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(g, cmap='Greys')\n",
    "axes[0,2].set_title('Canal Verde')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[0,3].imshow(b, cmap='Greys')\n",
    "axes[0,3].set_title('Canal Azul')\n",
    "axes[0,3].axis('off')\n",
    "\n",
    "\n",
    "# Canales individuales de color\n",
    "axes[1,0].imshow(r, cmap='Reds')\n",
    "axes[1,0].set_title('Solo Canal Rojo')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(g, cmap='Greens')\n",
    "axes[1,1].set_title('Solo Canal Verde')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(b, cmap='Blues')\n",
    "axes[1,2].set_title('Solo Canal Azul')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "# Reorganización de colores a bgr\n",
    "axes[1,3].imshow(img_gradiente)\n",
    "axes[1,3].set_title('Recombinar a BGR')\n",
    "axes[1,3].axis('off')\n",
    "\n",
    "plt.suptitle('Experimento 1: Separación de Canales RGB', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c901128",
   "metadata": {},
   "source": [
    "### Experimento 2: Análisis de Histogramas RGB\n",
    "\n",
    "Continuamos usando la **imagen de gradientes RGB** porque:\n",
    "- Permite comparar cómo se distribuyen los valores de intensidad en cada canal R, G, B\n",
    "- Los histogramas revelan si los canales están correlacionados o son independientes\n",
    "\n",
    "\n",
    "Visualizaremos los histogramas de cada canal RGB para entender la distribución estadística de los valores de color y identificar características importantes como picos, distribuciones uniformes, y posibles correlaciones entre canales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 2: Análisis de Histogramas RGB\n",
    "def analizar_histogramas_rgb(imagen):\n",
    "    \"\"\"Calcula y analiza los histogramas de cada canal RGB\"\"\"\n",
    "    b, g, r = cv2.split(cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Calcular histogramas\n",
    "    hist_r = cv2.calcHist([r], [0], None, [256], [0, 256])\n",
    "    hist_g = cv2.calcHist([g], [0], None, [256], [0, 256])\n",
    "    hist_b = cv2.calcHist([b], [0], None, [256], [0, 256])\n",
    "    \n",
    "    return hist_r, hist_g, hist_b, r, g, b\n",
    "\n",
    "# Calcular histogramas\n",
    "hist_r, hist_g, hist_b, r, g, b = analizar_histogramas_rgb(img_gradiente)\n",
    "\n",
    "# Visualizar histogramas RGB\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(hist_r, color='red', alpha=0.7, linewidth=2)\n",
    "axes[0].fill_between(range(256), hist_r.flatten(), alpha=0.3, color='red')\n",
    "axes[0].set_title('Histograma Canal Rojo')\n",
    "axes[0].set_xlabel('Intensidad')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(hist_g, color='green', alpha=0.7, linewidth=2)\n",
    "axes[1].fill_between(range(256), hist_g.flatten(), alpha=0.3, color='green')\n",
    "axes[1].set_title('Histograma Canal Verde')\n",
    "axes[1].set_xlabel('Intensidad')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(hist_b, color='blue', alpha=0.7, linewidth=2)\n",
    "axes[2].fill_between(range(256), hist_b.flatten(), alpha=0.3, color='blue')\n",
    "axes[2].set_title('Histograma Canal Azul')\n",
    "axes[2].set_xlabel('Intensidad')\n",
    "axes[2].set_ylabel('Frecuencia')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Experimento 2: Análisis de Histogramas RGB', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis estadístico\n",
    "\n",
    "print(f\"Canal Rojo - Media: {np.mean(r):.1f}, Desv.Est: {np.std(r):.1f}\")\n",
    "print(f\"Canal Verde - Media: {np.mean(g):.1f}, Desv.Est: {np.std(g):.1f}\")\n",
    "print(f\"Canal Azul - Media: {np.mean(b):.1f}, Desv.Est: {np.std(b):.1f}\")\n",
    "\n",
    "# Calcular correlaciones entre canales\n",
    "corr_rg = np.corrcoef(r.ravel(), g.ravel())[0,1]\n",
    "corr_rb = np.corrcoef(r.ravel(), b.ravel())[0,1]\n",
    "corr_gb = np.corrcoef(g.ravel(), b.ravel())[0,1]\n",
    "\n",
    "print(f\"\\nCorrelaciones entre canales:\")\n",
    "print(f\"Rojo-Verde: {corr_rg:.3f}\")\n",
    "print(f\"Rojo-Azul: {corr_rb:.3f}\")\n",
    "print(f\"Verde-Azul: {corr_gb:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c9a48b",
   "metadata": {},
   "source": [
    "## 2. Espacio de Color HSV (Hue, Saturation, Value)\n",
    "\n",
    "### Características\n",
    "- **H (Hue/Matiz)**: Tipo de color, rango 0-179° en OpenCV\n",
    "- **S (Saturation/Saturación)**: Pureza del color, rango 0-255\n",
    "- **V (Value/Valor)**: Brillo/luminosidad, rango 0-255\n",
    "- **Separación**: Separa información de color (H,S) de luminosidad (V)\n",
    "\n",
    "HSV separa la información cromática (H, S) de la luminosidad (V), lo que lo hace superior a RGB para:\n",
    "- Segmentación robusta por color bajo diferentes condiciones de iluminación\n",
    "- Detección de objetos basada en color\n",
    "- Aplicaciones donde el color es más importante que el brillo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e6498",
   "metadata": {},
   "source": [
    "Utilizamos dos imágenes para los experimentos:\n",
    "\n",
    "1. **Colores saturados**: Ideal para HSV porque:\n",
    "   - Permite ver claramente el canal de saturación en su máximo valor\n",
    "   - Cada banda representa un matiz específico, mostrando la distribución circular del Hue\n",
    "   - Al tener brillo uniforme, se puede aislar el efecto de H y S\n",
    "   - Cada color se puede segmentar fácilmente definiendo rangos de Hue\n",
    "\n",
    "2. **Espectro HSV completo**: Muestra todo el espacio HSV porque:\n",
    "   - **Eje horizontal**: Hue de 0° a 179° (todo el espectro de colores)\n",
    "   - **Eje vertical**: Saturación de 255 (arriba) a 0 (abajo)\n",
    "   - **Variación diagonal**: Value de 255 (esquina superior izq.) a 100 (esquina inferior der.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e8ef7",
   "metadata": {},
   "source": [
    "### Experimento 1: Separación de canales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis del espacio HSV\n",
    "def analizar_hsv(imagen):\n",
    "    \"\"\"Convierte imagen a HSV y analiza sus canales\"\"\"\n",
    "    # Convertir de BGR a HSV\n",
    "    hsv = cv2.cvtColor(imagen, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Separar canales\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    \n",
    "    return hsv, h, s, v\n",
    "\n",
    "def visualizar_hue_correctamente(canal_h):\n",
    "    altura, ancho = canal_h.shape\n",
    "    hsv_visual = np.zeros((altura, ancho, 3), dtype=np.uint8)\n",
    "    hsv_visual[:,:,0] = canal_h  # Hue original (0-179)\n",
    "    hsv_visual[:,:,1] = 255      # Saturación máxima\n",
    "    hsv_visual[:,:,2] = 255      # Valor máximo\n",
    "    \n",
    "    # Convertir de HSV a RGB para visualización\n",
    "    rgb_visual = cv2.cvtColor(hsv_visual, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return rgb_visual\n",
    "\n",
    "# Análisis con imagen de colores saturados y espectro HSV\n",
    "hsv_saturados, h_sat, s_sat, v_sat = analizar_hsv(img_colores)\n",
    "hsv_espectro, h_esp, s_esp, v_esp = analizar_hsv(img_espectro_hsv)\n",
    "\n",
    "# Visualizar análisis HSV\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Imagen de colores saturados\n",
    "axes[0,0].imshow(cv2.cvtColor(img_colores, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Original - Colores Saturados')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "# Canales HSV - Colores saturados\n",
    "axes[0,1].imshow(visualizar_hue_correctamente(h_sat))\n",
    "axes[0,1].set_title('Hue (Matiz)')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(s_sat, cmap='gray')\n",
    "axes[0,2].set_title('Saturation')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[0,3].imshow(v_sat, cmap='gray')\n",
    "axes[0,3].set_title('Value ')\n",
    "axes[0,3].axis('off')\n",
    "\n",
    "# Espectro HSV completo\n",
    "axes[1,0].imshow(cv2.cvtColor(img_espectro_hsv, cv2.COLOR_BGR2RGB))\n",
    "axes[1,0].set_title('Original - Espectro HSV')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(visualizar_hue_correctamente(h_esp))\n",
    "axes[1,1].set_title('Hue (Todo el Espectro)')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(s_esp, cmap='gray')\n",
    "axes[1,2].set_title('Saturation ')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "axes[1,3].imshow(v_esp, cmap='gray')\n",
    "axes[1,3].set_title('Value')\n",
    "axes[1,3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae31b11b",
   "metadata": {},
   "source": [
    "### Experimento 2: Segmentación de colores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Demostración de segmentación por color en HSV\n",
    "def segmentar_color_hsv(imagen, color_name, h_range, s_min=50, v_min=50):\n",
    "    \"\"\"Segmenta un color específico usando rangos HSV\"\"\"\n",
    "    hsv = cv2.cvtColor(imagen, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Crear máscara\n",
    "    if len(h_range) == 2 and h_range[0] < h_range[1]:\n",
    "        # Rango normal\n",
    "        lower = np.array([h_range[0], s_min, v_min])\n",
    "        upper = np.array([h_range[1], 255, 255])\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "    else:\n",
    "        # Rango que cruza 0° (ej: rojo) - h_range[0] > h_range[1]\n",
    "        # Crear dos máscaras: una para [0, h_range[1]] y otra para [h_range[0], 179]\n",
    "        lower1 = np.array([0, s_min, v_min])\n",
    "        upper1 = np.array([h_range[1], 255, 255])\n",
    "        lower2 = np.array([h_range[0], s_min, v_min])\n",
    "        upper2 = np.array([179, 255, 255])\n",
    "\n",
    "        mask1 = cv2.inRange(hsv, lower1, upper1)\n",
    "        mask2 = cv2.inRange(hsv, lower2, upper2)\n",
    "        mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # Aplicar máscara\n",
    "    resultado = cv2.bitwise_and(imagen, imagen, mask=mask)\n",
    "    \n",
    "    return mask, resultado\n",
    "\n",
    "# Segmentar diferentes colores\n",
    "mask_rojo, seg_rojo = segmentar_color_hsv(img_colores, \"Rojo\", [170, 10])\n",
    "mask_verde, seg_verde = segmentar_color_hsv(img_colores, \"Verde\", [40, 80])\n",
    "mask_azul, seg_azul = segmentar_color_hsv(img_colores, \"Azul\", [100, 130])\n",
    "\n",
    "# Mostrar segmentación\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "axes[0,0].imshow(img_colores)\n",
    "axes[0,0].set_title('Imagen Original')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(mask_rojo, cmap='gray')\n",
    "axes[0,1].set_title('Máscara Rojo')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(mask_verde, cmap='gray')\n",
    "axes[0,2].set_title('Máscara Verde')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[0,3].imshow(mask_azul, cmap='gray')\n",
    "axes[0,3].set_title('Máscara Azul')\n",
    "axes[0,3].axis('off')\n",
    "\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(seg_rojo)\n",
    "axes[1,1].set_title('Segmentación Rojo')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(seg_verde)\n",
    "axes[1,2].set_title('Segmentación Verde')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "axes[1,3].imshow(seg_azul)\n",
    "axes[1,3].set_title('Segmentación Azul')\n",
    "axes[1,3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30fb5c",
   "metadata": {},
   "source": [
    "## 3. Espacio de Color CIELAB (Lab)\n",
    "\n",
    "### Características\n",
    "- **L**: Lightness (luminosidad), rango 0-100\n",
    "- **a**: Verde-Rojo, rango aproximado -128 a +127\n",
    "- **b**: Azul-Amarillo, rango aproximado -128 a +127\n",
    "- **Uniforme perceptualmente**: Distancias euclidianas corresponden a diferencias percibidas\n",
    "- **Independiente del dispositivo**: Basado en percepción humana\n",
    "\n",
    "CIELAB es el único espacio uniforme perceptualmente en nuestro análisis, lo que significa:\n",
    "- Las distancias euclidianas corresponden a diferencias de color percibidas por el ojo humano\n",
    "- Permite medición objetiva de diferencias de color (ΔE)\n",
    "- Es independiente del dispositivo y basado en estándares internacionales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834bd276",
   "metadata": {},
   "source": [
    "### Experimento 1: Separación de Canales LAB\n",
    "\n",
    "**Colores Saturados:**\n",
    "- **Canales a* y b* bien definidos**: Los colores rojo/verde muestran extremos del eje a*, azul/amarillo del eje b*\n",
    "- Visualizar cómo CIELAB organiza el espacio cromático\n",
    "- Colores puros facilitan entender la transformación desde RGB\n",
    "\n",
    "**Expectro completo:**\n",
    "- **Transiciones suaves**: Muestran cómo LAB maneja cambios graduales de color\n",
    "- **Información de luminancia**: El canal L* separa claramente el brillo del color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b61151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis del espacio CIELAB\n",
    "def analizar_lab(imagen):\n",
    "    \"\"\"Convierte imagen a LAB y analiza sus canales\"\"\"\n",
    "    # Convertir de BGR a LAB\n",
    "    lab = cv2.cvtColor(imagen, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Separar canales\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    return lab, l, a, b\n",
    "\n",
    "# Análisis LAB\n",
    "lab_colores, l_col, a_col, b_col = analizar_lab(img_colores)\n",
    "lab_gradiente, l_grad, a_grad, b_grad = analizar_lab(img_espectro_hsv)\n",
    "\n",
    "\n",
    "# Visualizar análisis LAB\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Imagen de colores saturados\n",
    "axes[0,0].imshow(cv2.cvtColor(img_colores, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Original - Colores Saturados')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(l_col, cmap='gray')\n",
    "axes[0,1].set_title('L* (Luminosidad)')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(a_col, cmap='gray')  # Rojo-Verde\n",
    "axes[0,2].set_title('a* 0-255(Verde ← → Rojo)')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[0,3].imshow(b_col, cmap='gray')  # Amarillo-Azul\n",
    "axes[0,3].set_title('b* 0-255(Azul ← → Amarillo)')\n",
    "axes[0,3].axis('off')\n",
    "\n",
    "# Imagen gradiente\n",
    "axes[1,0].imshow(cv2.cvtColor(img_espectro_hsv, cv2.COLOR_BGR2RGB))\n",
    "axes[1,0].set_title('Original - espectro completo')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(l_grad, cmap='gray')\n",
    "axes[1,1].set_title('L* (Luminosidad)')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(a_grad, cmap='gray')\n",
    "axes[1,2].set_title('a* 0-255(Verde ← → Rojo)')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "axes[1,3].imshow(b_grad, cmap='gray')\n",
    "axes[1,3].set_title('b* 0-255 (Azul ← → Amarillo)')\n",
    "axes[1,3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c028ae5",
   "metadata": {},
   "source": [
    "### Experimento 2: Cálculo de Delta E:\n",
    "\n",
    "En este experimento veremos la poténcia de este espacio de colores para medir diferencias perceptuales entre colores de forma objetiva. Además, exploraremos otra capacidad muy potente de este espacio que es el de poder modificar la lumináncia de una imágen con facilidad. Para ello utilizaremos la imagen de los tonos de piel ya que es muy sensible a variaciones de luminancia (y además contiene colores vivos) y aumentaremos su lumináncia un 10% para medir perceptualmente el cambio de color que se obtiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88dbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 2: Cálculo de Delta E - Diferencias Perceptuales\n",
    "\n",
    "def simular_cambio_iluminacion(imagen, factor_luminancia=1.2):\n",
    "    \"\"\"Simula cambio de iluminación modificando el canal L* en LAB\"\"\"\n",
    "    lab = cv2.cvtColor(imagen, cv2.COLOR_BGR2LAB)\n",
    "    lab_modificada = lab.copy()\n",
    "    \n",
    "    # Modificar canal L* (luminancia)\n",
    "    lab_modificada[:,:,0] = np.clip(lab_modificada[:,:,0] * factor_luminancia, 0, 255)\n",
    "    \n",
    "    # Convertir de vuelta a BGR\n",
    "    img_modificada = cv2.cvtColor(lab_modificada, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return img_modificada, lab, lab_modificada\n",
    "\n",
    "def calcular_delta_e_avanzado(lab1, lab2):\n",
    "    \"\"\"Calcula Delta E entre dos imágenes LAB completas\"\"\"\n",
    "    # Asegurar que son float64 para evitar overflow\n",
    "    lab1 = lab1.astype(np.float64)\n",
    "    lab2 = lab2.astype(np.float64)\n",
    "    \n",
    "    # Calcular diferencias en cada canal\n",
    "    delta_l = lab1[:,:,0] - lab2[:,:,0]\n",
    "    delta_a = lab1[:,:,1] - lab2[:,:,1] \n",
    "    delta_b = lab1[:,:,2] - lab2[:,:,2]\n",
    "    \n",
    "    # Calcular Delta E usando la fórmula CIE76\n",
    "    delta_e = np.sqrt(delta_l**2 + delta_a**2 + delta_b**2)\n",
    "    \n",
    "    return delta_e, delta_l, delta_a, delta_b\n",
    "\n",
    "# Simular cambio de iluminación en colores saturados\n",
    "img_modificada, lab_original, lab_modificada = simular_cambio_iluminacion(img_piel, factor_luminancia=1.1)\n",
    "\n",
    "# Calcular Delta E\n",
    "delta_e, delta_l, delta_a, delta_b = calcular_delta_e_avanzado(lab_modificada, lab_original)\n",
    "\n",
    "# Crear visualización enfocada en Delta E\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "# Fila 1: Comparación visual\n",
    "axes[0,0].imshow(cv2.cvtColor(img_piel, cv2.COLOR_BGR2RGB))  # USAR ESPECTRO HSV\n",
    "axes[0,0].set_title('Imagen Original')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(cv2.cvtColor(img_modificada, cv2.COLOR_BGR2RGB))\n",
    "axes[0,1].set_title('Iluminación Aumentada (+10%)')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "# Mapa de calor Delta E (más prominente)\n",
    "im1 = axes[0,2].imshow(delta_e, cmap='hot', vmin=0, vmax=20)\n",
    "axes[0,2].set_title('Mapa Delta E\\n(Diferencias Perceptuales)')\n",
    "axes[0,2].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0,2], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Fila 2: Análisis Delta E\n",
    "# Histograma de Delta E\n",
    "axes[1,0].hist(delta_e.ravel(), bins=50, alpha=0.8, color='red', edgecolor='black')\n",
    "axes[1,0].set_title('Distribución de Delta E')\n",
    "axes[1,0].set_xlabel('Delta E')\n",
    "axes[1,0].set_ylabel('Frecuencia')\n",
    "axes[1,0].axvline(1, color='green', linestyle='--', linewidth=2, label='ΔE=1 (Imperceptible)')\n",
    "axes[1,0].axvline(5, color='orange', linestyle='--', linewidth=2, label='ΔE=5 (Apenas perceptible)')\n",
    "axes[1,0].axvline(10, color='red', linestyle='--', linewidth=2, label='ΔE=10 (Claramente visible)')\n",
    "axes[1,0].legend(fontsize=9)\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Solo diferencia de luminancia (lo que realmente cambia)\n",
    "diferencia_lum = np.abs(delta_l)\n",
    "im2 = axes[1,1].imshow(diferencia_lum, cmap='viridis')\n",
    "axes[1,1].set_title('Diferencia en L*')\n",
    "axes[1,1].axis('off')\n",
    "plt.colorbar(im2, ax=axes[1,1], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Estadísticas Delta E\n",
    "stats_text = f\"\"\"Estadísticas Delta E:\n",
    "• Media: {np.mean(delta_e):.2f}\n",
    "• Máximo: {np.max(delta_e):.2f}\n",
    "• Mínimo: {np.min(delta_e):.2f}\n",
    "• Desv. Est: {np.std(delta_e):.2f}\n",
    "\n",
    "Interpretación:\n",
    "• < 1: Imperceptible ({np.sum(delta_e < 1)/delta_e.size*100:.1f}%)\n",
    "• 1-5: Apenas perceptible ({np.sum((delta_e >= 1) & (delta_e < 5))/delta_e.size*100:.1f}%)\n",
    "• 5-10: Perceptible ({np.sum((delta_e >= 5) & (delta_e < 10))/delta_e.size*100:.1f}%)\n",
    "• > 10: Claramente visible ({np.sum(delta_e >= 10)/delta_e.size*100:.1f}%)\"\"\"\n",
    "\n",
    "axes[1,2].text(0.05, 0.95, stats_text, transform=axes[1,2].transAxes, fontsize=10,\n",
    "               verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "plt.suptitle('Experimento 2: Análisis Delta E - Diferencias Perceptuales (Solo Luminancia)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9adc24",
   "metadata": {},
   "source": [
    "## 4. Espacio de Color YCrCb\n",
    "\n",
    "### Características\n",
    "- **Y**: Luminancia (información de brillo), rango 0-255\n",
    "- **Cr**: Chrominance Red-difference (Rojo - Y), rango 0-255\n",
    "- **Cb**: Chrominance Blue-difference (Azul - Y), rango 0-255\n",
    "- **Separación**: Divide luminancia de información cromática\n",
    "- **Compresión**: Base para JPEG y muchos códecs de video\n",
    "\n",
    "YCrCb es fundamental en visión por ordenador por dos razones principales:\n",
    "- **Separación luminancia-cromaticidad**: Permite procesar brillo independientemente del color\n",
    "- **Detección de piel**: Los canales Cr-Cb forman clusters brillantemente definidos para tonos de piel humana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a52f5",
   "metadata": {},
   "source": [
    "### Experimento 1: Separación de Canales YCrCb\n",
    "\n",
    "**Para este experimento utilizaremos la imagen de tonos de piel:**\n",
    "- **Separación clara de componentes**: Los colores puros que contiene la imagen permiten ver cómo YCrCb descompone color vs luminancia\n",
    "- **Validación de la conversión**: Verificar que Y captura el brillo y Cr/Cb la información cromática\n",
    "- **Comparativa directa con los tonos de piel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89eadb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis del espacio YCrCb\n",
    "def analizar_ycrcb(imagen):\n",
    "    \"\"\"Convierte imagen a YCrCb y analiza sus canales\"\"\"\n",
    "    # Convertir de RGB a YCrCb\n",
    "    ycrcb = cv2.cvtColor(imagen, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Separar canales\n",
    "    y, cr, cb = cv2.split(ycrcb)\n",
    "    \n",
    "    return ycrcb, y, cr, cb\n",
    "\n",
    "# Análisis YCrCb usando las imágenes previamente cargadas\n",
    "\n",
    "ycrcb_piel, y_piel, cr_piel, cb_piel = analizar_ycrcb(img_piel)\n",
    "\n",
    "# Visualizar análisis YCrCb\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "# Imagen con tonos de piel\n",
    "axes[0].imshow(cv2.cvtColor(img_piel, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Tonos de Piel vs Otros Colores')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(y_piel, cmap='gray')\n",
    "axes[1].set_title('Y (Luminancia)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cr_piel, cmap='Reds')\n",
    "axes[2].set_title('Cr (Chrominance Rojo)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(cb_piel, cmap='Blues')\n",
    "axes[3].set_title('Cb (Chrominance Azul)')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6a0208",
   "metadata": {},
   "source": [
    "### Experimento 2: Detección de Tonos de Piel\n",
    "\n",
    "YCrCb se utiliza sobretodo por su gran rendimiento a la hora de detectar los tonos de colores correspondientes a la piel humana. En este experimento trataremos de detectar la sección que se corresponde con los tonos de piel de la imagen y veremos cual es la destribución típica de la crominancia para los tonos azules y rojos en la región de los colores de la piel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Demostración de detección de piel usando YCrCb\n",
    "def detectar_piel_ycrcb(imagen):\n",
    "    \"\"\"Detecta tonos de piel usando rangos típicos en YCrCb\"\"\"\n",
    "    ycrcb = cv2.cvtColor(imagen, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Rangos típicos para detección de piel en YCrCb\n",
    "    lower_skin = np.array([0, 133, 77])    # Límites inferiores\n",
    "    upper_skin = np.array([255, 173, 127]) # Límites superiores\n",
    "    \n",
    "    # Crear máscara\n",
    "    mask = cv2.inRange(ycrcb, lower_skin, upper_skin)\n",
    "    \n",
    "    # Aplicar máscara\n",
    "    resultado = cv2.bitwise_and(imagen, imagen, mask=mask)\n",
    "    \n",
    "    return mask, resultado\n",
    "\n",
    "# Detectar piel\n",
    "mask_piel, det_piel = detectar_piel_ycrcb(img_piel)\n",
    "\n",
    "# Análisis en espacio Cr-Cb (útil para detección de piel)\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(img_piel, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Imagen Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(mask_piel, cmap='gray')\n",
    "axes[1].set_title('Máscara de Detección de Piel')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(det_piel, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Piel Detectada')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# Scatter plot en espacio Cr-Cb\n",
    "axes[3].scatter(cr_piel.ravel(), cb_piel.ravel(), c=y_piel.ravel(), \n",
    "               cmap='viridis', alpha=0.6, s=1)\n",
    "axes[3].set_xlabel('Cr (Chrominance Rojo)')\n",
    "axes[3].set_ylabel('Cb (Chrominance Azul)')\n",
    "axes[3].set_title('Distribución en Espacio Cr-Cb')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "# Dibujar región típica de piel\n",
    "rect = Rectangle((133, 77), 173-133, 127-77, linewidth=2, \n",
    "                edgecolor='red', facecolor='none', linestyle='--')\n",
    "axes[3].add_patch(rect)\n",
    "axes[3].text(140, 80, 'Región\\nde Piel', color='red', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f5e52a",
   "metadata": {},
   "source": [
    "## 5. Escala de Grises y Aplicaciones Binarias\n",
    "\n",
    "### Características\n",
    "- **Un solo canal**: Valores de intensidad 0-255\n",
    "- **Reducción de dimensionalidad**: De 3 canales (RGB) a 1\n",
    "- **Conservación de información estructural**: Mantiene formas y texturas\n",
    "- **Menor complejidad computacional**: Procesamiento más rápido\n",
    "\n",
    "La escala de grises es crucial en visión por ordenador porque:\n",
    "- **Eficiencia computacional**: Reduce la dimensionalidad de 3 canales a 1\n",
    "- **Algoritmos clásicos**: Muchos algoritmos de detección están optimizados para un canal\n",
    "- **Información estructural**: Preserva formas, texturas y patrones sin la complejidad del color\n",
    "- **Aplicaciones específicas**: OCR, códigos de barras, análisis médico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f756a7",
   "metadata": {},
   "source": [
    "### Experimento 1: Diferentes conversiones a escala de grises\n",
    "En este experimento exploraremos varios de los diferentes métodos de conversión a escala de grises:\n",
    "1. **Promedio**: (R + G + B) / 3\n",
    "2. **Luminancia (ITU-R BT.709)**: 0.299R + 0.587G + 0.114B\n",
    "3. **Desaturación**: (max(R,G,B) + min(R,G,B)) / 2\n",
    "4. **Canal único**: Usar solo R, G, o B\n",
    "\n",
    "Para poder observar con mayor claridad los resultados utilizaremos la imagen de colores saturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa99fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de Escala de Grises y Aplicaciones Binarias\n",
    "\n",
    "def convertir_gris_metodos(imagen):\n",
    "    \"\"\"Compara diferentes métodos de conversión a escala de grises\"\"\"\n",
    "    # Método 1: Conversión estándar de OpenCV (usa ITU-R BT.709)\n",
    "    gris_opencv = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Método 2: Promedio simple\n",
    "    gris_promedio = np.mean(imagen, axis=2).astype(np.uint8)\n",
    "    \n",
    "    # Método 3: Luminancia manual (ITU-R BT.709)\n",
    "    b, g, r = cv2.split(imagen)\n",
    "    gris_luminancia = (0.114 * b + 0.587 * g + 0.299 * r).astype(np.uint8)\n",
    "    \n",
    "    # Método 4: Desaturación\n",
    "    gris_desaturacion = ((np.max(imagen, axis=2) + np.min(imagen, axis=2)) / 2).astype(np.uint8)\n",
    "    \n",
    "    # Método 5: Solo canal verde (más sensible a luminancia)\n",
    "    gris_verde = imagen[:,:,1]\n",
    "    \n",
    "    return gris_opencv, gris_promedio, gris_luminancia, gris_desaturacion, gris_verde\n",
    "\n",
    "# Analizar diferentes métodos de conversión\n",
    "metodos = convertir_gris_metodos(img_colores)\n",
    "nombres_metodos = ['OpenCV (ITU-R)', 'Promedio', 'Luminancia Manual', 'Desaturación', 'Solo Verde']\n",
    "\n",
    "# Visualizar comparación de métodos\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Imagen original\n",
    "axes[0,0].imshow(cv2.cvtColor(img_colores, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Imagen Original')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "# Métodos de conversión\n",
    "for i, (metodo, nombre) in enumerate(zip(metodos, nombres_metodos)):\n",
    "    fila = (i + 1) // 3\n",
    "    col = (i + 1) % 3\n",
    "    axes[fila, col].imshow(metodo, cmap='gray')\n",
    "    axes[fila, col].set_title(nombre)\n",
    "    axes[fila, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17ac110",
   "metadata": {},
   "source": [
    "### Experimento 2: Análisis de código de barras\n",
    "\n",
    "En este experimento analizaremos la poténcia que hay detrás de las aplicacianes más comunes de escala de grises: Las aplicaciones binárias para reconocimiento de código de barras. Para ello utilizaremos la imagen del código de barras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25728b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de código de barras\n",
    "def procesar_codigo_barras(imagen_barras):\n",
    "    \"\"\"Demuestra el procesamiento de códigos de barras\"\"\"\n",
    "    # Binarización usando diferentes métodos\n",
    "    \n",
    "    # Umbralización simple\n",
    "    _, binario_simple = cv2.threshold(imagen_barras, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Umbralización adaptativa\n",
    "    binario_adaptativo = cv2.adaptiveThreshold(imagen_barras, 255, \n",
    "                                             cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                             cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Umbralización de Otsu\n",
    "    _, binario_otsu = cv2.threshold(imagen_barras, 0, 255, \n",
    "                                   cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return binario_simple, binario_adaptativo, binario_otsu\n",
    "\n",
    "# Procesar código de barras\n",
    "bin_simple, bin_adaptativo, bin_otsu = procesar_codigo_barras(img_barras)\n",
    "\n",
    "# Análisis de perfil horizontal (típico para códigos de barras)\n",
    "perfil_horizontal = np.mean(img_barras, axis=0)\n",
    "perfil_binario = np.mean(bin_otsu, axis=0)\n",
    "\n",
    "# Visualizar análisis de código de barras\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "\n",
    "# Imagen original del código de barras\n",
    "axes[0,0].imshow(img_barras, cmap='gray')\n",
    "axes[0,0].set_title('Código de Barras Original')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "# Diferentes binarizaciones\n",
    "axes[0,1].imshow(bin_simple, cmap='gray')\n",
    "axes[0,1].set_title('Umbralización Simple')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(bin_adaptativo, cmap='gray')\n",
    "axes[0,2].set_title('Umbralización Adaptativa')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[1,0].imshow(bin_otsu, cmap='gray')\n",
    "axes[1,0].set_title('Umbralización Otsu')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "# Perfiles horizontales\n",
    "axes[1,1].plot(perfil_horizontal)\n",
    "axes[1,1].set_title('Perfil Intensidad Original')\n",
    "axes[1,1].set_xlabel('Posición X')\n",
    "axes[1,1].set_ylabel('Intensidad Media')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1,2].plot(perfil_binario)\n",
    "axes[1,2].set_title('Perfil Binario (Otsu)')\n",
    "axes[1,2].set_xlabel('Posición X')\n",
    "axes[1,2].set_ylabel('Intensidad Media')\n",
    "axes[1,2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3934b6bc",
   "metadata": {},
   "source": [
    "### Experimento 3: Detección de bordes\n",
    "En este experimento exploraremos los algoritmos de detección de bordes de Canny Sobel y el Laplaciano utilizando la imágen que pesenta diferentes formas geométricas de diferentes colores y formas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detección de bordes en escala de grises\n",
    "def detectar_bordes(imagen_gris):\n",
    "    \"\"\"Demuestra diferentes algoritmos de detección de bordes\"\"\"\n",
    "    # Suavizar imagen para reducir ruido\n",
    "    suavizada = cv2.GaussianBlur(imagen_gris, (5, 5), 0)\n",
    "    \n",
    "    # Algoritmos de detección de bordes\n",
    "    bordes_canny = cv2.Canny(suavizada, 50, 150)\n",
    "    \n",
    "    # Operadores Sobel\n",
    "    sobel_x = cv2.Sobel(suavizada, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(suavizada, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel_combined = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    sobel_combined = np.uint8(np.clip(sobel_combined, 0, 255))\n",
    "    \n",
    "    # Operador Laplaciano\n",
    "    laplaciano = cv2.Laplacian(suavizada, cv2.CV_64F)\n",
    "    laplaciano = np.uint8(np.clip(np.abs(laplaciano), 0, 255))\n",
    "    \n",
    "    return bordes_canny, sobel_combined, laplaciano\n",
    "\n",
    "# Convertir imagen de colores a escala de grises para detección de bordes\n",
    "gris_para_bordes = cv2.cvtColor(img_formas, cv2.COLOR_BGR2GRAY)\n",
    "canny, sobel, laplaciano = detectar_bordes(gris_para_bordes)\n",
    "\n",
    "# Visualizar detección de bordes\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(gris_para_bordes, cmap='gray')\n",
    "axes[0].set_title('Imagen en Escala de Grises')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(canny, cmap='gray')\n",
    "axes[1].set_title('Bordes Canny')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(sobel, cmap='gray')\n",
    "axes[2].set_title('Bordes Sobel')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(laplaciano, cmap='gray')\n",
    "axes[3].set_title('Bordes Laplaciano')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff676f4",
   "metadata": {},
   "source": [
    "## 6. Espacio de Color XYZ (CIE 1931)\n",
    "\n",
    "### Características\n",
    "- **X**: Componente tricromática roja (mezcla de conos L y M), rango 0-95.047\n",
    "- **Y**: Componente tricromática verde (luminancia), rango 0-100.000\n",
    "- **Z**: Componente tricromática azul (cono S), rango 0-108.883\n",
    "- **Estándar fundamental**: Base matemática para todos los demás espacios\n",
    "- **Independiente del dispositivo**: Basado en el observador estándar CIE\n",
    "\n",
    "### Importancia del Espacio XYZ\n",
    "\n",
    "XYZ es el **espacio de color fundamental** porque:\n",
    "- **Base matemática**: Todos los otros espacios (RGB, LAB, etc.) se definen en términos de XYZ\n",
    "- **Observador estándar**: Basado en estudios de percepción humana (CIE 1931)\n",
    "- **Calibración de dispositivos**: Esencial para caracterización de monitores, impresoras, cámaras\n",
    "- **Investigación científica**: Referencia absoluta para estudios de color\n",
    "- **Industria**: Base para estándares internacionales de color\n",
    "\n",
    "**Relación con otros espacios:**\n",
    "- **RGB → XYZ → LAB**: XYZ es el puente entre espacios dependientes e independientes del dispositivo\n",
    "- **Iluminante**: XYZ permite cambios de iluminante (D65, D50, etc.)\n",
    "- **Temperatura de color**: Fundamental para balance de blancos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980d6c9",
   "metadata": {},
   "source": [
    "### Experimento 1. Separación de Canales XYZ\n",
    "\n",
    "Para este experimento utilizaremos dos imágenes complementarias:\n",
    "\n",
    "1. **Colores saturados**: Permite observar cómo XYZ descompone los colores primarios\n",
    "   - **Canal X**: Dominante en rojos y magentas\n",
    "   - **Canal Y**: Representa la luminancia (similar a L* en LAB)\n",
    "   - **Canal Z**: Dominante en azules y cianes\n",
    "\n",
    "2. **Espectro HSV completo**: Muestra la distribución XYZ en todo el espacio cromático\n",
    "   - **Variación completa**: Permite ver cómo XYZ maneja diferentes combinaciones H-S-V\n",
    "   - **Análisis de luminancia**: El canal Y debe correlacionar con la percepción de brillo\n",
    "   - **Comparación con LAB**: Permite comparar Y con L* para validar la conversión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1155229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 1: Separación de Canales XYZ\n",
    "\n",
    "# Análisis del espacio XYZ\n",
    "def analizar_xyz(imagen):\n",
    "    \"\"\"Convierte imagen a XYZ y analiza sus canales\"\"\"\n",
    "    # Convertir de BGR a XYZ\n",
    "    xyz = cv2.cvtColor(imagen, cv2.COLOR_BGR2XYZ)\n",
    "    \n",
    "    # Separar canales\n",
    "    x, y, z = cv2.split(xyz)\n",
    "    \n",
    "    return xyz, x, y, z\n",
    "\n",
    "def normalizar_canal_xyz(canal, factor_normalizacion):\n",
    "    \"\"\"Normaliza un canal XYZ para visualización (0-255)\"\"\"\n",
    "    canal_norm = (canal.astype(np.float32) / factor_normalizacion * 255)\n",
    "    return np.clip(canal_norm, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Análisis XYZ usando colores saturados y espectro HSV\n",
    "xyz_colores, x_col, y_col, z_col = analizar_xyz(img_colores)\n",
    "xyz_gradiente, x_grad, y_grad, z_grad = analizar_xyz(img_espectro_hsv)\n",
    "\n",
    "# Normalizar canales XYZ para visualización\n",
    "# Factores de normalización basados en el iluminante D65\n",
    "x_col_norm = normalizar_canal_xyz(x_col, 95.047)\n",
    "y_col_norm = normalizar_canal_xyz(y_col, 100.000)\n",
    "z_col_norm = normalizar_canal_xyz(z_col, 108.883)\n",
    "\n",
    "x_grad_norm = normalizar_canal_xyz(x_grad, 95.047)\n",
    "y_grad_norm = normalizar_canal_xyz(y_grad, 100.000)\n",
    "z_grad_norm = normalizar_canal_xyz(z_grad, 108.883)\n",
    "\n",
    "# Visualizar análisis XYZ\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Imagen de colores saturados\n",
    "axes[0,0].imshow(cv2.cvtColor(img_colores, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Original - Colores Saturados')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(x_col_norm, cmap='gray')\n",
    "axes[0,1].set_title('X (Tricromática Roja)')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(y_col_norm, cmap='gray')\n",
    "axes[0,2].set_title('Y (Luminancia)')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[0,3].imshow(z_col_norm, cmap='gray')\n",
    "axes[0,3].set_title('Z (Tricromática Azul)')\n",
    "axes[0,3].axis('off')\n",
    "\n",
    "# Espectro HSV completo\n",
    "axes[1,0].imshow(cv2.cvtColor(img_espectro_hsv, cv2.COLOR_BGR2RGB))\n",
    "axes[1,0].set_title('Original - Espectro HSV')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(x_grad_norm, cmap='gray')\n",
    "axes[1,1].set_title('X (Espectro Completo)')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(y_grad_norm, cmap='gray')\n",
    "axes[1,2].set_title('Y (Luminancia Espectro)')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "axes[1,3].imshow(z_grad_norm, cmap='gray')\n",
    "axes[1,3].set_title('Z (Espectro Completo)')\n",
    "axes[1,3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b48428",
   "metadata": {},
   "source": [
    "### Experimento 2: Luminancia Lineal vs Luminancia Perceptual\n",
    "\n",
    "Este experimento explora la distinción entre **luminancia lineal** y **luminancia perceptual**.\n",
    "\n",
    "La Luminancia Lineal (Canal Y de XYZ) representa la intensidad física de luz emitida o reflejada y es proporcional a la radiancia medida por sensores físicos.\n",
    "Es fundamental para cálculos físicos como balance de blancos, calibración de cámaras...\n",
    "\n",
    "Por otro lado, la Luminancia Perceptual (Canal L* de CIELAB) representa cómo el ojo humano percibe el brillo y es esencial para aplicaciones visuales como edición de imágenes, interfaces...\n",
    "\n",
    "Compararemos el canal Y (XYZ) con L* (LAB) usando dos imágenes:\n",
    "- **Tonos de piel**: Muy sensibles a variaciones de luminancia, críticos en aplicaciones de visión por ordenador\n",
    "- **Espectro HSV**: Amplio rango cromático para análisis estadístico robusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 2: Comparación de Luminancia XYZ vs LAB\n",
    "\n",
    "# Función para extraer y comparar luminancias\n",
    "def comparar_luminancias_xyz_lab(imagen):\n",
    "    \"\"\"Compara el canal Y de XYZ con el canal L* de LAB\"\"\"\n",
    "    # Convertir a XYZ\n",
    "    xyz = cv2.cvtColor(imagen, cv2.COLOR_BGR2XYZ)\n",
    "    y_xyz = xyz[:,:,1]  # Canal Y (luminancia lineal)\n",
    "    \n",
    "    # Convertir a LAB\n",
    "    lab = cv2.cvtColor(imagen, cv2.COLOR_BGR2LAB)\n",
    "    l_lab = lab[:,:,0]  # Canal L* (luminancia perceptual)\n",
    "    \n",
    "    # Normalizar Y de XYZ para comparación visual\n",
    "    y_xyz_norm = (y_xyz / 100.0 * 255).astype(np.uint8)\n",
    "    \n",
    "    return y_xyz, l_lab, y_xyz_norm, xyz, lab\n",
    "\n",
    "# Comparar luminancias usando tonos de piel e espectro HSV\n",
    "y_piel, l_piel, y_piel_norm, xyz_piel, lab_piel = comparar_luminancias_xyz_lab(img_piel)\n",
    "y_espectro, l_espectro, y_espectro_norm, xyz_espectro, lab_espectro = comparar_luminancias_xyz_lab(img_espectro_hsv)\n",
    "\n",
    "# Visualizar comparación de luminancias\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Fila 1: Tonos de piel\n",
    "axes[0,0].imshow(cv2.cvtColor(img_piel, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Original - Tonos de Piel')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(y_piel_norm, cmap='gray')\n",
    "axes[0,1].set_title('Y (XYZ Luminancia Lineal)')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(l_piel, cmap='gray')\n",
    "axes[0,2].set_title('L* (LAB Luminancia Perceptual)')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "# Diferencia entre luminancias\n",
    "diff_piel = np.abs(y_piel_norm.astype(np.float32) - l_piel.astype(np.float32))\n",
    "im1 = axes[0,3].imshow(diff_piel, cmap='hot')\n",
    "axes[0,3].set_title('Diferencia |Y - L*|')\n",
    "axes[0,3].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0,3], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Fila 2: Espectro HSV\n",
    "axes[1,0].imshow(cv2.cvtColor(img_espectro_hsv, cv2.COLOR_BGR2RGB))\n",
    "axes[1,0].set_title('Original - Espectro HSV')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(y_espectro_norm, cmap='gray')\n",
    "axes[1,1].set_title('Y (XYZ Luminancia Lineal)')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(l_espectro, cmap='gray')\n",
    "axes[1,2].set_title('L* (LAB Luminancia Perceptual)')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "# Scatter plot Y vs L*\n",
    "axes[1,3].scatter(y_piel_norm.ravel(), l_piel.ravel(), alpha=0.6, s=1, c='blue', label='Tonos Piel')\n",
    "axes[1,3].scatter(y_espectro_norm.ravel(), l_espectro.ravel(), alpha=0.4, s=1, c='red', label='Espectro HSV')\n",
    "axes[1,3].plot([0, 255], [0, 255], 'k--', alpha=0.8, label='Y = L*')\n",
    "axes[1,3].set_xlabel('Y (XYZ Luminancia)')\n",
    "axes[1,3].set_ylabel('L* (LAB Luminancia)')\n",
    "axes[1,3].set_title('Correlación Y vs L*')\n",
    "axes[1,3].legend()\n",
    "axes[1,3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis cuantitativo\n",
    "corr_piel = np.corrcoef(y_piel_norm.ravel(), l_piel.ravel())[0,1]\n",
    "corr_espectro = np.corrcoef(y_espectro_norm.ravel(), l_espectro.ravel())[0,1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
