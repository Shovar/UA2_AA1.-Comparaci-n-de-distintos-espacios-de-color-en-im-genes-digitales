{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8c33de",
   "metadata": {},
   "source": [
    "# Entregable 2: Comparación de distintos espacios de color en imágenes digitales\n",
    "\n",
    "Este proyecto presenta un análisis completo de diferentes espacios de color y sus aplicaciones prácticas en visión por ordenador.\n",
    "\n",
    "## Creación de imágenes de Prueba\n",
    "Las imágenes utilizadas en los experimentos se gestionan automáticamente:\n",
    "- **Primera ejecución**: Se crean y guardan en la carpeta `data/`\n",
    "- **Ejecuciones posteriores**: Se cargan desde `data/`\n",
    "- **Imágenes incluidas**: \n",
    "  - `gradiente_rgb.png` - Gradientes de colores primarios\n",
    "  - `colores_saturados.png` - Colores puros para análisis HSV\n",
    "  - `espectro_hsv.png` - Espectro completo HSV (Hue horizontal, Saturación vertical)\n",
    "  - `codigo_barras.png` - Patrón binario para análisis en escala de grises\n",
    "  - `tonos_piel.png` - Tonos de piel para detección YCrCb\n",
    "\n",
    "## Espacios de Color a Analizar\n",
    "1. **RGB** - Red, Green, Blue\n",
    "2. **HSV** - Hue, Saturation, Value  \n",
    "3. **CIELAB (Lab)** - Lightness, a*, b*\n",
    "4. **YCrCb** - Luminance, Chrominance\n",
    "5. **Escala de Grises** - Para aplicaciones binarias\n",
    "6. **XYZ** - CIE 1931 color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88475a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Configuración de matplotlib\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Función auxiliar para mostrar múltiples imágenes\n",
    "def mostrar_imagenes(imagenes, titulos, filas=2, columnas=3, figsize=(15, 10)):\n",
    "    \"\"\"\n",
    "    Función para mostrar múltiples imágenes en una grilla\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(filas, columnas, figsize=figsize)\n",
    "    if filas == 1:\n",
    "        axes = [axes]\n",
    "    if columnas == 1:\n",
    "        axes = [[ax] for ax in axes]\n",
    "    \n",
    "    for i, (img, titulo) in enumerate(zip(imagenes, titulos)):\n",
    "        fila = i // columnas\n",
    "        col = i % columnas\n",
    "        \n",
    "        if len(img.shape) == 3:\n",
    "            # Imagen en color (RGB)\n",
    "            axes[fila][col].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            # Imagen en escala de grises\n",
    "            axes[fila][col].imshow(img, cmap='gray')\n",
    "        \n",
    "        axes[fila][col].set_title(titulo)\n",
    "        axes[fila][col].axis('off')\n",
    "    \n",
    "    # Ocultar axes no utilizados\n",
    "    for i in range(len(imagenes), filas * columnas):\n",
    "        fila = i // columnas\n",
    "        col = i % columnas\n",
    "        axes[fila][col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26329391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestión de imágenes de prueba - Creación y carga desde data/\n",
    "def crear_imagen_gradiente_rgb():\n",
    "    \"\"\"Crea una imagen con gradientes de colores RGB\"\"\"\n",
    "    altura, ancho = 300, 400\n",
    "    imagen = np.zeros((altura, ancho, 3), dtype=np.uint8)\n",
    "    #Las imágenes en OpenCV usan el formato BGR en lugar de RGB\n",
    "\n",
    "        # Gradiente horizontal de rojo\n",
    "    for x in range(ancho//3):\n",
    "        imagen[:300, x] = [0, 0, int(255 * x / (ancho//3))]\n",
    "\n",
    "    # Gradiente horizontal de verde\n",
    "    for x in range(ancho//3, 2*ancho//3):\n",
    "        imagen[:300, x] = [0, int(255 * (x - ancho//3) / (ancho//3)), 0]\n",
    "\n",
    "    # Gradiente horizontal de azul\n",
    "    for x in range(2*ancho//3, ancho):\n",
    "        imagen[:300, x] = [int(255 * (x - 2*ancho//3) / (ancho//3)), 0, 0]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    return imagen\n",
    "\n",
    "def crear_imagen_colores_saturados():\n",
    "    \"\"\"Crea una imagen con colores saturados para análisis HSV\"\"\"\n",
    "    altura, ancho = 300, 400\n",
    "    imagen = np.zeros((altura, ancho, 3), dtype=np.uint8)\n",
    "    \n",
    "     # Colores en formato BGR (Blue, Green, Red)\n",
    "    colores = [\n",
    "        [0, 0, 255],      # Rojo en BGR\n",
    "        [0, 255, 255],    # Amarillo en BGR  \n",
    "        [0, 255, 0],      # Verde en BGR\n",
    "        [255, 255, 0],    # Cian en BGR\n",
    "        [255, 0, 0],      # Azul en BGR\n",
    "        [255, 0, 255]     # Magenta en BGR\n",
    "    ]\n",
    "    \n",
    "    ancho_banda = ancho // len(colores)\n",
    "    for i, color in enumerate(colores):\n",
    "        x_inicio = i * ancho_banda\n",
    "        x_fin = min((i + 1) * ancho_banda, ancho)\n",
    "        imagen[:, x_inicio:x_fin] = color\n",
    "    \n",
    "    return imagen\n",
    "\n",
    "def crear_codigo_barras():\n",
    "    \"\"\"Crea una imagen de código de barras\"\"\"\n",
    "    altura, ancho = 200, 400\n",
    "    imagen = np.ones((altura, ancho), dtype=np.uint8) * 255\n",
    "    \n",
    "    # Patrón de barras\n",
    "    patron = [3, 1, 2, 1, 3, 2, 1, 3, 1, 2, 3, 1, 2, 1, 3]\n",
    "    x = 50\n",
    "    color_actual = 0  # 0 para negro, 255 para blanco\n",
    "    \n",
    "    for ancho_barra in patron:\n",
    "        imagen[:, x:x+ancho_barra*8] = color_actual\n",
    "        color_actual = 255 - color_actual  # Alternar entre negro y blanco\n",
    "        x += ancho_barra * 8\n",
    "    \n",
    "    return imagen\n",
    "\n",
    "def crear_imagen_espectro_hsv():\n",
    "    \"\"\"Crea una imagen que muestra todo el espectro HSV de manera educativa\n",
    "    - Eje X (horizontal): Hue de 0° a 179° (todo el espectro de colores)\n",
    "    - Eje Y (vertical): Saturación de 255 (arriba) a 0 (abajo)\n",
    "    - Profundidad (diagonal): Value varía para mostrar el espacio HSV completo\n",
    "    \"\"\"\n",
    "    altura, ancho = 300, 400\n",
    "    imagen = np.zeros((altura, ancho, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Crear espectro HSV completo con variación en los tres canales\n",
    "    for y in range(altura):\n",
    "        for x in range(ancho):\n",
    "            # Calcular valores HSV\n",
    "            # Hue: varía horizontalmente de 0 a 179 (rango OpenCV)\n",
    "            h = int((x / ancho) * 179)\n",
    "            \n",
    "            # Saturation: varía verticalmente de 255 (arriba) a 0 (abajo)\n",
    "            s = int(255 * (1 - y / altura))\n",
    "            \n",
    "            # Value: varía diagonalmente para crear un espectro 3D proyectado en 2D\n",
    "            # Esquina superior izquierda: V máximo (255)\n",
    "            # Esquina inferior derecha: V mínimo (pero no negro total)\n",
    "            # Esto permite ver cómo interactúan H, S y V\n",
    "            factor_diagonal = (x / ancho + (1 - y / altura)) / 2\n",
    "            v = int(100 + 155 * factor_diagonal)  # Rango: 100-255 para mantener visibilidad\n",
    "            \n",
    "            # Crear pixel HSV y convertir a BGR\n",
    "            hsv_pixel = np.array([[[h, s, v]]], dtype=np.uint8)\n",
    "            bgr_pixel = cv2.cvtColor(hsv_pixel, cv2.COLOR_HSV2BGR)\n",
    "            imagen[y, x] = bgr_pixel[0, 0]\n",
    "    \n",
    "    return imagen\n",
    "\n",
    "def crear_imagen_con_piel():\n",
    "    \"\"\"Crea una imagen con gradiente de tonos de piel para demostrar YCrCb\"\"\"\n",
    "    altura, ancho = 300, 400\n",
    "    imagen = np.zeros((altura, ancho, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Definir tonos de piel extremos para el gradiente (valores BGR)\n",
    "    piel_clara = np.array([180, 200, 240], dtype=np.float32)    # Piel muy clara (rosada)\n",
    "    piel_oscura = np.array([35, 60, 85], dtype=np.float32)     # Piel muy oscura\n",
    "    \n",
    "    # Crear gradiente horizontal de tonos de piel (parte superior)\n",
    "    for x in range(ancho):\n",
    "        # Calcular factor de interpolación (0.0 a 1.0)\n",
    "        factor = x / (ancho - 1)\n",
    "        \n",
    "        # Interpolar entre piel clara y oscura\n",
    "        color_piel = piel_clara * (1 - factor) + piel_oscura * factor\n",
    "        \n",
    "        # Asignar color a la mitad superior de la imagen\n",
    "        imagen[:altura//2, x] = color_piel.astype(np.uint8)\n",
    "    \n",
    "    # Añadir otros colores para comparación (parte inferior)\n",
    "    otros_colores = [\n",
    "        [0, 0, 255],        # Rojo\n",
    "        [0, 255, 0],        # Verde  \n",
    "        [255, 0, 0],        # Azul\n",
    "        [255, 255, 255],    # Blanco\n",
    "        [128, 128, 128],    # Gris\n",
    "        [0, 255, 255],      # Amarillo\n",
    "    ]\n",
    "    \n",
    "    seccion_ancho = ancho // len(otros_colores)\n",
    "    \n",
    "    # Añadir otros colores en la parte inferior\n",
    "    for i, color in enumerate(otros_colores):\n",
    "        x_inicio = i * seccion_ancho\n",
    "        x_fin = min((i + 1) * seccion_ancho, ancho)\n",
    "        imagen[altura//2:, x_inicio:x_fin] = color\n",
    "    \n",
    "    return imagen\n",
    "\n",
    "def cargar_o_crear_imagenes():\n",
    "    \"\"\"Carga las imágenes desde data/ o las crea si no existen\"\"\"\n",
    "    # Crear directorio data si no existe\n",
    "    data_dir = 'data'\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "        print(f\"Directorio '{data_dir}' creado\")\n",
    "    \n",
    "    # Rutas de las imágenes\n",
    "    rutas = {\n",
    "        'gradiente': os.path.join(data_dir, 'gradiente_rgb.png'),\n",
    "        'colores': os.path.join(data_dir, 'colores_saturados.png'),\n",
    "        'espectro_hsv': os.path.join(data_dir, 'espectro_hsv.png'),\n",
    "        'barras': os.path.join(data_dir, 'codigo_barras.png'),\n",
    "        'piel': os.path.join(data_dir, 'tonos_piel.png')\n",
    "    }\n",
    "    \n",
    "    imagenes = {}\n",
    "    \n",
    "    # Cargar o crear cada imagen\n",
    "    for nombre, ruta in rutas.items():\n",
    "        if os.path.exists(ruta):\n",
    "            if nombre == 'barras':\n",
    "                # Código de barras es escala de grises\n",
    "                imagenes[nombre] = cv2.imread(ruta, cv2.IMREAD_GRAYSCALE)\n",
    "            else:\n",
    "                # Imágenes en color\n",
    "                imagenes[nombre] = cv2.imread(ruta)\n",
    "            print(f\"✓ Cargada imagen existente: {nombre}\")\n",
    "        else:\n",
    "            # Crear imagen sintética\n",
    "            if nombre == 'gradiente':\n",
    "                imagenes[nombre] = crear_imagen_gradiente_rgb()\n",
    "            elif nombre == 'colores':\n",
    "                imagenes[nombre] = crear_imagen_colores_saturados()\n",
    "            elif nombre == 'espectro_hsv':\n",
    "                imagenes[nombre] = crear_imagen_espectro_hsv()\n",
    "            elif nombre == 'barras':\n",
    "                imagenes[nombre] = crear_codigo_barras()\n",
    "            elif nombre == 'piel':\n",
    "                imagenes[nombre] = crear_imagen_con_piel()\n",
    "            \n",
    "            # Guardar imagen\n",
    "            cv2.imwrite(ruta, imagenes[nombre])\n",
    "            print(f\"✓ Creada y guardada nueva imagen: {nombre}\")\n",
    "    \n",
    "    return imagenes['gradiente'], imagenes['colores'], imagenes['espectro_hsv'], imagenes['barras'], imagenes['piel']\n",
    "\n",
    "# Cargar o crear las imágenes de prueba\n",
    "img_gradiente, img_colores, img_espectro_hsv, img_barras, img_piel = cargar_o_crear_imagenes()\n",
    "\n",
    "# Mostrar las imágenes cargadas/creadas\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(img_gradiente, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Gradientes RGB')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(img_colores, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title('Colores Saturados')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(img_espectro_hsv, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Espectro HSV Completo')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(img_barras, cmap='gray')\n",
    "axes[3].set_title('Código de Barras')\n",
    "axes[3].axis('off')\n",
    "\n",
    "axes[4].imshow(cv2.cvtColor(img_piel, cv2.COLOR_BGR2RGB))\n",
    "axes[4].set_title('Tonos de Piel')\n",
    "axes[4].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Sistema de gestión de imágenes configurado\")\n",
    "print(\"Las imágenes se guardan en 'data/' y se reutilizan en ejecuciones futuras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad6875",
   "metadata": {},
   "source": [
    "## 1. Espacio de Color RGB (Red, Green, Blue)\n",
    "\n",
    "### Características\n",
    "- Los colores se forman sumando intensidades de rojo, verde y azul\n",
    "- Cada canal tiene valores de 0-255 (8 bits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d369948",
   "metadata": {},
   "source": [
    "### Experimento 1: Separación y Visualización de Canales RGB\n",
    "\n",
    "Utilizamos la imagen de **gradientes RGB** porque:\n",
    "- Cada sección contiene principalmente un color primario (rojo, verde, azul)\n",
    "- Los gradientes muestran cómo cambia la intensidad de cada canal de 0 a 255\n",
    "- Permite observar cómo los canales RGB se superponen en las zonas de transición\n",
    "\n",
    "Separaremos los canales R, G, B de la imagen y los visualizaremos tanto en escala de grises (para ver la contribución individual) como en color (para ver el efecto visual de cada canal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f14e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 1: Separación y Visualización de Canales RGB\n",
    "r,g,b = cv2.split(cv2.cvtColor(img_gradiente, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "# Visualizar análisis RGB - Separación de canales\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 10))\n",
    "\n",
    "# Imagen original\n",
    "axes[0,0].imshow(cv2.cvtColor(img_gradiente, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Imagen Original')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "# Canales individuales en escala de grises\n",
    "axes[0,1].imshow(r, cmap='Greys')\n",
    "axes[0,1].set_title('Canal Rojo')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(g, cmap='Greys')\n",
    "axes[0,2].set_title('Canal Verde')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[0,3].imshow(b, cmap='Greys')\n",
    "axes[0,3].set_title('Canal Azul')\n",
    "axes[0,3].axis('off')\n",
    "\n",
    "\n",
    "# Canales individuales de color\n",
    "axes[1,0].imshow(r, cmap='Reds')\n",
    "axes[1,0].set_title('Solo Canal Rojo')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(g, cmap='Greens')\n",
    "axes[1,1].set_title('Solo Canal Verde')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(b, cmap='Blues')\n",
    "axes[1,2].set_title('Solo Canal Azul')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "# Reorganización de colores a bgr\n",
    "axes[1,3].imshow(img_gradiente)\n",
    "axes[1,3].set_title('Recombinar a BGR')\n",
    "axes[1,3].axis('off')\n",
    "\n",
    "plt.suptitle('Experimento 1: Separación de Canales RGB', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c901128",
   "metadata": {},
   "source": [
    "### Experimento 2: Análisis de Histogramas RGB\n",
    "\n",
    "Continuamos usando la **imagen de gradientes RGB** porque:\n",
    "- Permite comparar cómo se distribuyen los valores de intensidad en cada canal R, G, B\n",
    "- Los histogramas revelan si los canales están correlacionados o son independientes\n",
    "\n",
    "\n",
    "Visualizaremos los histogramas de cada canal RGB para entender la distribución estadística de los valores de color y identificar características importantes como picos, distribuciones uniformes, y posibles correlaciones entre canales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e914bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 2: Análisis de Histogramas RGB\n",
    "def analizar_histogramas_rgb(imagen):\n",
    "    \"\"\"Calcula y analiza los histogramas de cada canal RGB\"\"\"\n",
    "    b, g, r = cv2.split(cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Calcular histogramas\n",
    "    hist_r = cv2.calcHist([r], [0], None, [256], [0, 256])\n",
    "    hist_g = cv2.calcHist([g], [0], None, [256], [0, 256])\n",
    "    hist_b = cv2.calcHist([b], [0], None, [256], [0, 256])\n",
    "    \n",
    "    return hist_r, hist_g, hist_b, r, g, b\n",
    "\n",
    "# Calcular histogramas\n",
    "hist_r, hist_g, hist_b, r, g, b = analizar_histogramas_rgb(img_gradiente)\n",
    "\n",
    "# Visualizar histogramas RGB\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].plot(hist_r, color='red', alpha=0.7, linewidth=2)\n",
    "axes[0].fill_between(range(256), hist_r.flatten(), alpha=0.3, color='red')\n",
    "axes[0].set_title('Histograma Canal Rojo')\n",
    "axes[0].set_xlabel('Intensidad')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(hist_g, color='green', alpha=0.7, linewidth=2)\n",
    "axes[1].fill_between(range(256), hist_g.flatten(), alpha=0.3, color='green')\n",
    "axes[1].set_title('Histograma Canal Verde')\n",
    "axes[1].set_xlabel('Intensidad')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(hist_b, color='blue', alpha=0.7, linewidth=2)\n",
    "axes[2].fill_between(range(256), hist_b.flatten(), alpha=0.3, color='blue')\n",
    "axes[2].set_title('Histograma Canal Azul')\n",
    "axes[2].set_xlabel('Intensidad')\n",
    "axes[2].set_ylabel('Frecuencia')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Experimento 2: Análisis de Histogramas RGB', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis estadístico\n",
    "\n",
    "print(f\"Canal Rojo - Media: {np.mean(r):.1f}, Desv.Est: {np.std(r):.1f}\")\n",
    "print(f\"Canal Verde - Media: {np.mean(g):.1f}, Desv.Est: {np.std(g):.1f}\")\n",
    "print(f\"Canal Azul - Media: {np.mean(b):.1f}, Desv.Est: {np.std(b):.1f}\")\n",
    "\n",
    "# Calcular correlaciones entre canales\n",
    "corr_rg = np.corrcoef(r.ravel(), g.ravel())[0,1]\n",
    "corr_rb = np.corrcoef(r.ravel(), b.ravel())[0,1]\n",
    "corr_gb = np.corrcoef(g.ravel(), b.ravel())[0,1]\n",
    "\n",
    "print(f\"\\nCorrelaciones entre canales:\")\n",
    "print(f\"Rojo-Verde: {corr_rg:.3f}\")\n",
    "print(f\"Rojo-Azul: {corr_rb:.3f}\")\n",
    "print(f\"Verde-Azul: {corr_gb:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c9a48b",
   "metadata": {},
   "source": [
    "## 2. Espacio de Color HSV (Hue, Saturation, Value)\n",
    "\n",
    "### Características\n",
    "- **H (Hue/Matiz)**: Tipo de color, rango 0-179° en OpenCV\n",
    "- **S (Saturation/Saturación)**: Pureza del color, rango 0-255\n",
    "- **V (Value/Valor)**: Brillo/luminosidad, rango 0-255\n",
    "- **Separación**: Separa información de color (H,S) de luminosidad (V)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e6498",
   "metadata": {},
   "source": [
    "### Experimentos Planificados y Justificación\n",
    "\n",
    "HSV separa la información cromática (H, S) de la luminosidad (V), lo que lo hace superior a RGB para:\n",
    "- Segmentación robusta por color bajo diferentes condiciones de iluminación\n",
    "- Detección de objetos basada en color\n",
    "- Aplicaciones donde el color es más importante que el brillo\n",
    "\n",
    "Utilizamos dos tipos de imágenes complementarias:\n",
    "\n",
    "1. **Colores saturados**: Ideal para HSV porque:\n",
    "   - Permite ver claramente el canal de saturación en su máximo valor\n",
    "   - Cada banda representa un matiz específico, mostrando la distribución circular del Hue\n",
    "   - Al tener brillo uniforme, se puede aislar el efecto de H y S\n",
    "   - Cada color se puede segmentar fácilmente definiendo rangos de Hue\n",
    "\n",
    "2. **Espectro HSV completo**: Muestra todo el espacio HSV porque:\n",
    "   - **Eje horizontal**: Hue de 0° a 179° (todo el espectro de colores)\n",
    "   - **Eje vertical**: Saturación de 255 (arriba) a 0 (abajo)\n",
    "   - **Variación diagonal**: Value de 255 (esquina superior izq.) a 100 (esquina inferior der.)\n",
    "   - **Visualización 3D en 2D**: Permite ver la interacción entre los tres canales H, S, V\n",
    "   - **Educativo**: Muestra cómo HSV organiza todo el espacio de color tridimensional\n",
    "\n",
    "**Experimentos a realizar:**\n",
    "1. **Separación de canales**: Analizar H, S, V en ambas imágenes\n",
    "2. **Segmentación por color**: Usar colores saturados para demostrar robustez\n",
    "3. **Análisis del espectro**: Mostrar la distribución completa HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019b1a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis del espacio HSV\n",
    "def analizar_hsv(imagen):\n",
    "    \"\"\"Convierte imagen a HSV y analiza sus canales\"\"\"\n",
    "    # Convertir de BGR a HSV\n",
    "    hsv = cv2.cvtColor(imagen, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Separar canales\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    \n",
    "    return hsv, h, s, v\n",
    "\n",
    "def visualizar_hue_correctamente(canal_h):\n",
    "    altura, ancho = canal_h.shape\n",
    "    hsv_visual = np.zeros((altura, ancho, 3), dtype=np.uint8)\n",
    "    hsv_visual[:,:,0] = canal_h  # Hue original (0-179)\n",
    "    hsv_visual[:,:,1] = 255      # Saturación máxima\n",
    "    hsv_visual[:,:,2] = 255      # Valor máximo\n",
    "    \n",
    "    # Convertir de HSV a RGB para visualización\n",
    "    rgb_visual = cv2.cvtColor(hsv_visual, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return rgb_visual\n",
    "\n",
    "# Análisis con imagen de colores saturados y espectro HSV\n",
    "hsv_saturados, h_sat, s_sat, v_sat = analizar_hsv(img_colores)\n",
    "hsv_espectro, h_esp, s_esp, v_esp = analizar_hsv(img_espectro_hsv)\n",
    "\n",
    "# Visualizar análisis HSV\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Imagen de colores saturados\n",
    "axes[0,0].imshow(cv2.cvtColor(img_colores, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Original - Colores Saturados')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "# Canales HSV - Colores saturados\n",
    "axes[0,1].imshow(visualizar_hue_correctamente(h_sat))\n",
    "axes[0,1].set_title('Hue (Matiz)')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(s_sat, cmap='gray')\n",
    "axes[0,2].set_title('Saturation')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[0,3].imshow(v_sat, cmap='gray')\n",
    "axes[0,3].set_title('Value ')\n",
    "axes[0,3].axis('off')\n",
    "\n",
    "# Espectro HSV completo\n",
    "axes[1,0].imshow(cv2.cvtColor(img_espectro_hsv, cv2.COLOR_BGR2RGB))\n",
    "axes[1,0].set_title('Original - Espectro HSV')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(visualizar_hue_correctamente(h_esp))\n",
    "axes[1,1].set_title('Hue (Todo el Espectro)')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(s_esp, cmap='gray')\n",
    "axes[1,2].set_title('Saturation ')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "axes[1,3].imshow(v_esp, cmap='gray')\n",
    "axes[1,3].set_title('Value')\n",
    "axes[1,3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae0f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Demostración de segmentación por color en HSV\n",
    "def segmentar_color_hsv(imagen, color_name, h_range, s_min=50, v_min=50):\n",
    "    \"\"\"Segmenta un color específico usando rangos HSV\"\"\"\n",
    "    hsv = cv2.cvtColor(imagen, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Crear máscara\n",
    "    if len(h_range) == 2 and h_range[0] < h_range[1]:\n",
    "        # Rango normal\n",
    "        lower = np.array([h_range[0], s_min, v_min])\n",
    "        upper = np.array([h_range[1], 255, 255])\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "    else:\n",
    "        # Rango que cruza 0° (ej: rojo) - h_range[0] > h_range[1]\n",
    "        # Crear dos máscaras: una para [0, h_range[1]] y otra para [h_range[0], 179]\n",
    "        lower1 = np.array([0, s_min, v_min])\n",
    "        upper1 = np.array([h_range[1], 255, 255])\n",
    "        lower2 = np.array([h_range[0], s_min, v_min])\n",
    "        upper2 = np.array([179, 255, 255])\n",
    "\n",
    "        mask1 = cv2.inRange(hsv, lower1, upper1)\n",
    "        mask2 = cv2.inRange(hsv, lower2, upper2)\n",
    "        mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # Aplicar máscara\n",
    "    resultado = cv2.bitwise_and(imagen, imagen, mask=mask)\n",
    "    \n",
    "    return mask, resultado\n",
    "\n",
    "# Segmentar diferentes colores\n",
    "mask_rojo, seg_rojo = segmentar_color_hsv(img_colores, \"Rojo\", [170, 10])\n",
    "mask_verde, seg_verde = segmentar_color_hsv(img_colores, \"Verde\", [40, 80])\n",
    "mask_azul, seg_azul = segmentar_color_hsv(img_colores, \"Azul\", [100, 130])\n",
    "\n",
    "# Mostrar segmentación\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "axes[0,0].imshow(img_colores)\n",
    "axes[0,0].set_title('Imagen Original')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(mask_rojo, cmap='gray')\n",
    "axes[0,1].set_title('Máscara Rojo')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(mask_verde, cmap='gray')\n",
    "axes[0,2].set_title('Máscara Verde')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[0,3].imshow(mask_azul, cmap='gray')\n",
    "axes[0,3].set_title('Máscara Azul')\n",
    "axes[0,3].axis('off')\n",
    "\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(seg_rojo)\n",
    "axes[1,1].set_title('Segmentación Rojo')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(seg_verde)\n",
    "axes[1,2].set_title('Segmentación Verde')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "axes[1,3].imshow(seg_azul)\n",
    "axes[1,3].set_title('Segmentación Azul')\n",
    "axes[1,3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30fb5c",
   "metadata": {},
   "source": [
    "## 3. Espacio de Color CIELAB (Lab)\n",
    "\n",
    "### Características\n",
    "- **L**: Lightness (luminosidad), rango 0-100\n",
    "- **a**: Verde-Rojo, rango aproximado -128 a +127\n",
    "- **b**: Azul-Amarillo, rango aproximado -128 a +127\n",
    "- **Uniforme perceptualmente**: Distancias euclidianas corresponden a diferencias percibidas\n",
    "- **Independiente del dispositivo**: Basado en percepción humana\n",
    "\n",
    "CIELAB es el único espacio uniforme perceptualmente en nuestro análisis, lo que significa:\n",
    "- Las distancias euclidianas corresponden a diferencias de color percibidas por el ojo humano\n",
    "- Permite medición objetiva de diferencias de color (ΔE)\n",
    "- Es independiente del dispositivo y basado en estándares internacionales\n",
    "- Esencial para control de calidad en industrias donde el color es crítico\n",
    "\n",
    "**Experimentos a realizar:**\n",
    "1. **Separación de canales**: Analizar L, a*, b* en colores saturados y gradientes\n",
    "2. **Cálculo de Delta E**: Medir diferencias perceptuales entre colores\n",
    "3. **Análisis de modificación**: Simular cambios de iluminación y medir impacto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834bd276",
   "metadata": {},
   "source": [
    "### Experimento 1: Separación de Canales LAB\n",
    "\n",
    "**Colores Saturados:**\n",
    "- **Canales a* y b* bien definidos**: Los colores rojo/verde muestran extremos del eje a*, azul/amarillo del eje b*\n",
    "- Visualizar cómo CIELAB organiza el espacio cromático\n",
    "- Colores puros facilitan entender la transformación desde RGB\n",
    "\n",
    "**Expectro completo RGB:**\n",
    "- **Transiciones suaves**: Muestran cómo LAB maneja cambios graduales de color\n",
    "- **Información de luminancia**: El canal L* separa claramente el brillo del color\n",
    "- **Comparación perceptual**: Permite ver si las transiciones son más uniformes que en RGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b61151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis del espacio CIELAB\n",
    "def analizar_lab(imagen):\n",
    "    \"\"\"Convierte imagen a LAB y analiza sus canales\"\"\"\n",
    "    # Convertir de BGR a LAB\n",
    "    lab = cv2.cvtColor(imagen, cv2.COLOR_BGR2LAB)\n",
    "    \n",
    "    # Separar canales\n",
    "    l, a, b = cv2.split(lab)\n",
    "    \n",
    "    return lab, l, a, b\n",
    "\n",
    "def calcular_delta_e(lab1, lab2):\n",
    "    \"\"\"Calcula la diferencia de color Delta E entre dos colores LAB\"\"\"\n",
    "    # Convertir a float para evitar overflow\n",
    "    lab1 = lab1.astype(np.float64)\n",
    "    lab2 = lab2.astype(np.float64)\n",
    "    \n",
    "    # Calcular diferencias\n",
    "    delta_l = lab1[:,:,0] - lab2[:,:,0]\n",
    "    delta_a = lab1[:,:,1] - lab2[:,:,1]\n",
    "    delta_b = lab1[:,:,2] - lab2[:,:,2]\n",
    "    \n",
    "    # Delta E (CIE76)\n",
    "    delta_e = np.sqrt(delta_l**2 + delta_a**2 + delta_b**2)\n",
    "    \n",
    "    return delta_e\n",
    "\n",
    "# Análisis LAB\n",
    "lab_colores, l_col, a_col, b_col = analizar_lab(img_colores)\n",
    "lab_gradiente, l_grad, a_grad, b_grad = analizar_lab(img_espectro_hsv)\n",
    "\n",
    "\n",
    "# Visualizar análisis LAB\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Imagen de colores saturados\n",
    "axes[0,0].imshow(cv2.cvtColor(img_colores, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Original - Colores Saturados')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(l_col, cmap='gray')\n",
    "axes[0,1].set_title('L* (Luminosidad)')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(a_col, cmap='gray')  # Rojo-Verde\n",
    "axes[0,2].set_title('a* 0-255(Verde ← → Rojo)')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[0,3].imshow(b_col, cmap='gray')  # Amarillo-Azul\n",
    "axes[0,3].set_title('b* 0-255(Azul ← → Amarillo)')\n",
    "axes[0,3].axis('off')\n",
    "\n",
    "# Imagen gradiente\n",
    "axes[1,0].imshow(cv2.cvtColor(img_espectro_hsv, cv2.COLOR_BGR2RGB))\n",
    "axes[1,0].set_title('Original - espectro completo')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(l_grad, cmap='gray')\n",
    "axes[1,1].set_title('L* (Luminosidad)')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(a_grad, cmap='gray')\n",
    "axes[1,2].set_title('a* 0-255(Verde ← → Rojo)')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "axes[1,3].imshow(b_grad, cmap='gray')\n",
    "axes[1,3].set_title('b* 0-255 (Azul ← → Amarillo)')\n",
    "axes[1,3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c028ae5",
   "metadata": {},
   "source": [
    "### Experimento 2: Cálculo de Delta E:\n",
    "\n",
    "Medir diferencias perceptuales entre colores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88dbd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimento 2: Cálculo de Delta E - Diferencias Perceptuales\n",
    "\n",
    "def simular_cambio_iluminacion(imagen, factor_luminancia=1.2):\n",
    "    \"\"\"Simula cambio de iluminación modificando el canal L* en LAB\"\"\"\n",
    "    lab = cv2.cvtColor(imagen, cv2.COLOR_BGR2LAB)\n",
    "    lab_modificada = lab.copy()\n",
    "    \n",
    "    # Modificar canal L* (luminancia)\n",
    "    lab_modificada[:,:,0] = np.clip(lab_modificada[:,:,0] * factor_luminancia, 0, 255)\n",
    "    \n",
    "    # Convertir de vuelta a BGR\n",
    "    img_modificada = cv2.cvtColor(lab_modificada, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    return img_modificada, lab, lab_modificada\n",
    "\n",
    "def calcular_delta_e_avanzado(lab1, lab2):\n",
    "    \"\"\"Calcula Delta E entre dos imágenes LAB completas\"\"\"\n",
    "    # Asegurar que son float64 para evitar overflow\n",
    "    lab1 = lab1.astype(np.float64)\n",
    "    lab2 = lab2.astype(np.float64)\n",
    "    \n",
    "    # Calcular diferencias en cada canal\n",
    "    delta_l = lab1[:,:,0] - lab2[:,:,0]\n",
    "    delta_a = lab1[:,:,1] - lab2[:,:,1] \n",
    "    delta_b = lab1[:,:,2] - lab2[:,:,2]\n",
    "    \n",
    "    # Calcular Delta E usando la fórmula CIE76\n",
    "    delta_e = np.sqrt(delta_l**2 + delta_a**2 + delta_b**2)\n",
    "    \n",
    "    return delta_e, delta_l, delta_a, delta_b\n",
    "\n",
    "# Simular cambio de iluminación en colores saturados\n",
    "img_modificada, lab_original, lab_modificada = simular_cambio_iluminacion(img_colores, factor_luminancia=1.3)\n",
    "\n",
    "# Calcular Delta E\n",
    "delta_e, delta_l, delta_a, delta_b = calcular_delta_e_avanzado(lab_original, lab_modificada)\n",
    "\n",
    "# Análisis estadístico del Delta E\n",
    "print(\"=== Análisis de Diferencias Perceptuales (Delta E) ===\")\n",
    "print(f\"Delta E - Media: {np.mean(delta_e):.2f}\")\n",
    "print(f\"Delta E - Máximo: {np.max(delta_e):.2f}\")\n",
    "print(f\"Delta E - Mínimo: {np.min(delta_e):.2f}\")\n",
    "print(f\"Delta E - Desv. Estándar: {np.std(delta_e):.2f}\")\n",
    "\n",
    "print(f\"\\nInterpretación Delta E:\")\n",
    "print(f\"• ΔE < 1: Diferencia imperceptible\")\n",
    "print(f\"• ΔE 1-3: Apenas perceptible por experto\")\n",
    "print(f\"• ΔE 3-6: Perceptible por observador promedio\")\n",
    "print(f\"• ΔE > 6: Diferencia claramente visible\")\n",
    "\n",
    "# Análisis por componentes\n",
    "print(f\"\\nContribución por canal:\")\n",
    "print(f\"• Canal L* (Luminancia): Media Δ = {np.mean(np.abs(delta_l)):.2f}\")\n",
    "print(f\"• Canal a* (Verde-Rojo): Media Δ = {np.mean(np.abs(delta_a)):.2f}\")\n",
    "print(f\"• Canal b* (Azul-Amarillo): Media Δ = {np.mean(np.abs(delta_b)):.2f}\")\n",
    "\n",
    "# Crear visualización completa\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "# Fila 1: Imágenes originales y modificadas\n",
    "axes[0,0].imshow(cv2.cvtColor(img_colores, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Imagen Original')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "axes[0,1].imshow(cv2.cvtColor(img_modificada, cv2.COLOR_BGR2RGB))\n",
    "axes[0,1].set_title('Iluminación Aumentada (+30%)')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "# Mapa de calor Delta E\n",
    "im1 = axes[0,2].imshow(delta_e, cmap='hot')\n",
    "axes[0,2].set_title('Mapa Delta E')\n",
    "axes[0,2].axis('off')\n",
    "plt.colorbar(im1, ax=axes[0,2], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Histograma de Delta E\n",
    "axes[0,3].hist(delta_e.ravel(), bins=50, alpha=0.7, color='red', edgecolor='black')\n",
    "axes[0,3].set_title('Distribución Delta E')\n",
    "axes[0,3].set_xlabel('Delta E')\n",
    "axes[0,3].set_ylabel('Frecuencia')\n",
    "axes[0,3].axvline(1, color='green', linestyle='--', label='ΔE=1')\n",
    "axes[0,3].axvline(3, color='orange', linestyle='--', label='ΔE=3')\n",
    "axes[0,3].axvline(6, color='red', linestyle='--', label='ΔE=6')\n",
    "axes[0,3].legend(fontsize=8)\n",
    "axes[0,3].grid(True, alpha=0.3)\n",
    "\n",
    "# Fila 2: Componentes LAB originales\n",
    "axes[1,0].imshow(lab_original[:,:,0], cmap='gray')\n",
    "axes[1,0].set_title('L* Original')\n",
    "axes[1,0].axis('off')\n",
    "\n",
    "axes[1,1].imshow(lab_original[:,:,1], cmap='RdGy_r')\n",
    "axes[1,1].set_title('a* Original (Verde-Rojo)')\n",
    "axes[1,1].axis('off')\n",
    "\n",
    "axes[1,2].imshow(lab_original[:,:,2], cmap='RdYlBu_r')\n",
    "axes[1,2].set_title('b* Original (Azul-Amarillo)')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "# Diferencia de luminancia\n",
    "diferencia_lum = np.abs(delta_l)\n",
    "im = axes[1,3].imshow(diferencia_lum, cmap='viridis')\n",
    "axes[1,3].set_title('Diferencia en L*')\n",
    "axes[1,3].axis('off')\n",
    "plt.colorbar(im, ax=axes[1,3], fraction=0.046, pad=0.04)\n",
    "\n",
    "# Fila 3: Componentes LAB modificados\n",
    "axes[2,0].imshow(lab_modificada[:,:,0], cmap='gray')\n",
    "axes[2,0].set_title('L* Modificada (+30%)')\n",
    "axes[2,0].axis('off')\n",
    "\n",
    "axes[2,1].imshow(lab_modificada[:,:,1], cmap='RdGy_r')\n",
    "axes[2,1].set_title('a* Modificada')\n",
    "axes[2,1].axis('off')\n",
    "\n",
    "axes[2,2].imshow(lab_modificada[:,:,2], cmap='RdYlBu_r')\n",
    "axes[2,2].set_title('b* Modificada')\n",
    "axes[2,2].axis('off')\n",
    "\n",
    "# Análisis de regiones específicas\n",
    "# Seleccionar región de cada color para análisis detallado\n",
    "ancho_banda = img_colores.shape[1] // 6\n",
    "regiones_colores = ['Azul', 'Cian', 'Verde', 'Amarillo', 'Rojo', 'Magenta']\n",
    "delta_e_por_region = []\n",
    "\n",
    "for i in range(6):\n",
    "    x_inicio = i * ancho_banda\n",
    "    x_fin = min((i + 1) * ancho_banda, img_colores.shape[1])\n",
    "    region_delta_e = delta_e[:, x_inicio:x_fin]\n",
    "    delta_e_por_region.append(np.mean(region_delta_e))\n",
    "\n",
    "axes[2,3].bar(range(len(regiones_colores)), delta_e_por_region, \n",
    "              color=['blue', 'cyan', 'green', 'yellow', 'red', 'magenta'], alpha=0.7)\n",
    "axes[2,3].set_title('Delta E por Color')\n",
    "axes[2,3].set_xlabel('Color')\n",
    "axes[2,3].set_ylabel('Delta E Promedio')\n",
    "axes[2,3].set_xticks(range(len(regiones_colores)))\n",
    "axes[2,3].set_xticklabels(regiones_colores, rotation=45, fontsize=8)\n",
    "axes[2,3].grid(True, alpha=0.3)\n",
    "\n",
    "# Añadir líneas de referencia\n",
    "axes[2,3].axhline(1, color='green', linestyle='--', alpha=0.8, label='Imperceptible')\n",
    "axes[2,3].axhline(3, color='orange', linestyle='--', alpha=0.8, label='Apenas perceptible')\n",
    "axes[2,3].axhline(6, color='red', linestyle='--', alpha=0.8, label='Claramente visible')\n",
    "axes[2,3].legend(fontsize=7)\n",
    "\n",
    "plt.suptitle('Experimento 2: Análisis Delta E - Diferencias Perceptuales en CIELAB', fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Análisis de sensibilidad por color\n",
    "print(f\"\\n=== Sensibilidad Delta E por Color ===\")\n",
    "for i, (color, delta) in enumerate(zip(regiones_colores, delta_e_por_region)):\n",
    "    if delta < 1:\n",
    "        interpretacion = \"Imperceptible\"\n",
    "    elif delta < 3:\n",
    "        interpretacion = \"Apenas perceptible\"\n",
    "    elif delta < 6:\n",
    "        interpretacion = \"Perceptible\"\n",
    "    else:\n",
    "        interpretacion = \"Claramente visible\"\n",
    "    \n",
    "    print(f\"• {color:8}: ΔE = {delta:.2f} ({interpretacion})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9adc24",
   "metadata": {},
   "source": [
    "## 4. Espacio de Color YCrCb\n",
    "\n",
    "### Características\n",
    "- **Y**: Luminancia (información de brillo), rango 0-255\n",
    "- **Cr**: Chrominance Red-difference (Rojo - Y), rango 0-255\n",
    "- **Cb**: Chrominance Blue-difference (Azul - Y), rango 0-255\n",
    "- **Separación**: Divide luminancia de información cromática\n",
    "- **Compresión**: Base para JPEG y muchos códecs de video\n",
    "\n",
    "### Experimentos\n",
    "\n",
    "YCrCb es fundamental en visión por ordenador por dos razones principales:\n",
    "- **Separación luminancia-cromaticidad**: Permite procesar brillo independientemente del color\n",
    "- **Detección de piel**: Los canales Cr-Cb forman clusters brillantemente definidos para tonos de piel humana\n",
    "\n",
    "**Experimentos a realizar:**\n",
    "1. **Separación de canales**: Analizar Y, Cr, Cb individualmente en colores saturados\n",
    "2. **Detección de piel**: Segmentación automática usando clustering en Cr-Cb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a52f5",
   "metadata": {},
   "source": [
    "### Experimento 1: Separación de Canales YCrCb\n",
    "\n",
    "**Justificación de la imagen (Colores Saturados):**\n",
    "- **Separación clara de componentes**: Los colores puros permiten ver cómo YCrCb descompone color vs luminancia\n",
    "- **Validación de la conversión**: Verificar que Y captura el brillo y Cr/Cb la información cromática\n",
    "- Colores distintivos facilitan entender la transformación\n",
    "\n",
    "**Descripción del experimento:**\n",
    "Analizaremos cómo YCrCb separa la información de luminancia (Y) de la cromática (Cr, Cb) usando colores saturados puros.\n",
    "- Comparación directa con el rendimiento en tonos de piel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89eadb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis del espacio YCrCb\n",
    "def analizar_ycrcb(imagen):\n",
    "    \"\"\"Convierte imagen a YCrCb y analiza sus canales\"\"\"\n",
    "    # Convertir de RGB a YCrCb\n",
    "    ycrcb = cv2.cvtColor(imagen, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Separar canales\n",
    "    y, cr, cb = cv2.split(ycrcb)\n",
    "    \n",
    "    return ycrcb, y, cr, cb\n",
    "\n",
    "# Análisis YCrCb usando las imágenes previamente cargadas\n",
    "\n",
    "ycrcb_piel, y_piel, cr_piel, cb_piel = analizar_ycrcb(img_piel)\n",
    "\n",
    "# Visualizar análisis YCrCb\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 8))\n",
    "\n",
    "# Imagen con tonos de piel\n",
    "axes[0].imshow(cv2.cvtColor(img_piel, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Tonos de Piel vs Otros Colores')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(y_piel, cmap='gray')\n",
    "axes[1].set_title('Y (Luminancia)')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cr_piel, cmap='Reds')\n",
    "axes[2].set_title('Cr (Chrominance Rojo)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(cb_piel, cmap='Blues')\n",
    "axes[3].set_title('Cb (Chrominance Azul)')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6caf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Demostración de detección de piel usando YCrCb\n",
    "def detectar_piel_ycrcb(imagen):\n",
    "    \"\"\"Detecta tonos de piel usando rangos típicos en YCrCb\"\"\"\n",
    "    ycrcb = cv2.cvtColor(imagen, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    # Rangos típicos para detección de piel en YCrCb\n",
    "    lower_skin = np.array([0, 133, 77])    # Límites inferiores\n",
    "    upper_skin = np.array([255, 173, 127]) # Límites superiores\n",
    "    \n",
    "    # Crear máscara\n",
    "    mask = cv2.inRange(ycrcb, lower_skin, upper_skin)\n",
    "    \n",
    "    # Aplicar máscara\n",
    "    resultado = cv2.bitwise_and(imagen, imagen, mask=mask)\n",
    "    \n",
    "    return mask, resultado\n",
    "\n",
    "# Detectar piel\n",
    "mask_piel, det_piel = detectar_piel_ycrcb(img_piel)\n",
    "\n",
    "# Análisis en espacio Cr-Cb (útil para detección de piel)\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(cv2.cvtColor(img_piel, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title('Imagen Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(mask_piel, cmap='gray')\n",
    "axes[1].set_title('Máscara de Detección de Piel')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(det_piel, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title('Piel Detectada')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# Scatter plot en espacio Cr-Cb\n",
    "axes[3].scatter(cr_piel.ravel(), cb_piel.ravel(), c=y_piel.ravel(), \n",
    "               cmap='viridis', alpha=0.6, s=1)\n",
    "axes[3].set_xlabel('Cr (Chrominance Rojo)')\n",
    "axes[3].set_ylabel('Cb (Chrominance Azul)')\n",
    "axes[3].set_title('Distribución en Espacio Cr-Cb')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "# Dibujar región típica de piel\n",
    "rect = Rectangle((133, 77), 173-133, 127-77, linewidth=2, \n",
    "                edgecolor='red', facecolor='none', linestyle='--')\n",
    "axes[3].add_patch(rect)\n",
    "axes[3].text(140, 80, 'Región\\nde Piel', color='red', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f5e52a",
   "metadata": {},
   "source": [
    "## 5. Escala de Grises y Aplicaciones Binarias\n",
    "\n",
    "### Características\n",
    "- **Un solo canal**: Valores de intensidad 0-255\n",
    "- **Reducción de dimensionalidad**: De 3 canales (RGB) a 1\n",
    "- **Conservación de información estructural**: Mantiene formas y texturas\n",
    "- **Menor complejidad computacional**: Procesamiento más rápido\n",
    "\n",
    "### Métodos de Conversión\n",
    "1. **Promedio**: (R + G + B) / 3\n",
    "2. **Luminancia (ITU-R BT.709)**: 0.299R + 0.587G + 0.114B\n",
    "3. **Desaturación**: (max(R,G,B) + min(R,G,B)) / 2\n",
    "4. **Canal único**: Usar solo R, G, o B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e3b12",
   "metadata": {},
   "source": [
    "\n",
    "La escala de grises es crucial en visión por ordenador porque:\n",
    "- **Eficiencia computacional**: Reduce la dimensionalidad de 3 canales a 1\n",
    "- **Algoritmos clásicos**: Muchos algoritmos de detección están optimizados para un canal\n",
    "- **Información estructural**: Preserva formas, texturas y patrones sin la complejidad del color\n",
    "- **Aplicaciones específicas**: OCR, códigos de barras, análisis médico\n",
    "\n",
    "**¿Por qué usar múltiples tipos de imágenes?**\n",
    "\n",
    "1. **Colores saturados para comparación de métodos**:\n",
    "   - **Diferentes algoritmos de conversión**: Promedio, luminancia, desaturación, canal único\n",
    "   - **Impacto visual variable**: Cada método produce resultados diferentes en colores saturados\n",
    "   - **Evaluación de calidad**: Permite comparar qué método preserva mejor la información perceptual\n",
    "\n",
    "2. **Código de barras para aplicaciones binarias**:\n",
    "   - **Patrón específico**: Diseñado para demostrar la efectividad en reconocimiento de patrones\n",
    "   - **Alto contraste**: Ideal para técnicas de umbralización y binarización\n",
    "   - **Aplicación real**: Representa una de las aplicaciones más comunes de escala de grises\n",
    "   - **Análisis de perfil**: Las barras permiten análisis unidimensional característico\n",
    "\n",
    "3. **Gradientes para detección de bordes**:\n",
    "   - **Transiciones suaves**: Ideales para algoritmos de detección de bordes (Canny, Sobel, Laplaciano)\n",
    "   - **Información estructural**: Demuestra cómo la escala de grises preserva formas y contornos\n",
    "   - **Comparación de operadores**: Permite evaluar diferentes técnicas de detección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa99fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de Escala de Grises y Aplicaciones Binarias\n",
    "\n",
    "def convertir_gris_metodos(imagen):\n",
    "    \"\"\"Compara diferentes métodos de conversión a escala de grises\"\"\"\n",
    "    # Método 1: Conversión estándar de OpenCV (usa ITU-R BT.709)\n",
    "    gris_opencv = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Método 2: Promedio simple\n",
    "    gris_promedio = np.mean(imagen, axis=2).astype(np.uint8)\n",
    "    \n",
    "    # Método 3: Luminancia manual (ITU-R BT.709)\n",
    "    b, g, r = cv2.split(imagen)\n",
    "    gris_luminancia = (0.114 * b + 0.587 * g + 0.299 * r).astype(np.uint8)\n",
    "    \n",
    "    # Método 4: Desaturación\n",
    "    gris_desaturacion = ((np.max(imagen, axis=2) + np.min(imagen, axis=2)) / 2).astype(np.uint8)\n",
    "    \n",
    "    # Método 5: Solo canal verde (más sensible a luminancia)\n",
    "    gris_verde = imagen[:,:,1]\n",
    "    \n",
    "    return gris_opencv, gris_promedio, gris_luminancia, gris_desaturacion, gris_verde\n",
    "\n",
    "# Analizar diferentes métodos de conversión\n",
    "metodos = convertir_gris_metodos(img_colores)\n",
    "nombres_metodos = ['OpenCV (ITU-R)', 'Promedio', 'Luminancia Manual', 'Desaturación', 'Solo Verde']\n",
    "\n",
    "# Visualizar comparación de métodos\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Imagen original\n",
    "axes[0,0].imshow(cv2.cvtColor(img_colores, cv2.COLOR_BGR2RGB))\n",
    "axes[0,0].set_title('Imagen Original')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "# Métodos de conversión\n",
    "for i, (metodo, nombre) in enumerate(zip(metodos, nombres_metodos)):\n",
    "    fila = (i + 1) // 3\n",
    "    col = (i + 1) % 3\n",
    "    axes[fila, col].imshow(metodo, cmap='gray')\n",
    "    axes[fila, col].set_title(nombre)\n",
    "    axes[fila, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25728b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de código de barras\n",
    "def procesar_codigo_barras(imagen_barras):\n",
    "    \"\"\"Demuestra el procesamiento de códigos de barras\"\"\"\n",
    "    # Binarización usando diferentes métodos\n",
    "    \n",
    "    # Umbralización simple\n",
    "    _, binario_simple = cv2.threshold(imagen_barras, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Umbralización adaptativa\n",
    "    binario_adaptativo = cv2.adaptiveThreshold(imagen_barras, 255, \n",
    "                                             cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                             cv2.THRESH_BINARY, 11, 2)\n",
    "    \n",
    "    # Umbralización de Otsu\n",
    "    _, binario_otsu = cv2.threshold(imagen_barras, 0, 255, \n",
    "                                   cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    return binario_simple, binario_adaptativo, binario_otsu\n",
    "\n",
    "# Procesar código de barras\n",
    "bin_simple, bin_adaptativo, bin_otsu = procesar_codigo_barras(img_barras)\n",
    "\n",
    "# Análisis de perfil horizontal (típico para códigos de barras)\n",
    "perfil_horizontal = np.mean(img_barras, axis=0)\n",
    "perfil_binario = np.mean(bin_otsu, axis=0)\n",
    "\n",
    "# Visualizar análisis de código de barras\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "# Imagen original del código de barras\n",
    "axes[0,0].imshow(img_barras, cmap='gray')\n",
    "axes[0,0].set_title('Código de Barras Original')\n",
    "axes[0,0].axis('off')\n",
    "\n",
    "# Diferentes binarizaciones\n",
    "axes[0,1].imshow(bin_simple, cmap='gray')\n",
    "axes[0,1].set_title('Umbralización Simple')\n",
    "axes[0,1].axis('off')\n",
    "\n",
    "axes[0,2].imshow(bin_adaptativo, cmap='gray')\n",
    "axes[0,2].set_title('Umbralización Adaptativa')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[0,3].imshow(bin_otsu, cmap='gray')\n",
    "axes[0,3].set_title('Umbralización Otsu')\n",
    "axes[0,3].axis('off')\n",
    "\n",
    "# Perfiles horizontales\n",
    "axes[1,0].plot(perfil_horizontal)\n",
    "axes[1,0].set_title('Perfil Intensidad Original')\n",
    "axes[1,0].set_xlabel('Posición X')\n",
    "axes[1,0].set_ylabel('Intensidad Media')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1,1].plot(perfil_binario)\n",
    "axes[1,1].set_title('Perfil Binario (Otsu)')\n",
    "axes[1,1].set_xlabel('Posición X')\n",
    "axes[1,1].set_ylabel('Intensidad Media')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Histograma de la imagen original\n",
    "axes[1,2].hist(img_barras.ravel(), bins=256, alpha=0.7, color='gray')\n",
    "axes[1,2].set_title('Histograma Original')\n",
    "axes[1,2].set_xlabel('Intensidad')\n",
    "axes[1,2].set_ylabel('Frecuencia')\n",
    "axes[1,2].axvline(127, color='red', linestyle='--', label='Umbral 127')\n",
    "axes[1,2].legend()\n",
    "\n",
    "# Diferencias entre métodos\n",
    "diferencia = np.abs(bin_simple.astype(np.float32) - bin_otsu.astype(np.float32))\n",
    "axes[1,3].imshow(diferencia, cmap='hot')\n",
    "axes[1,3].set_title('Diferencia: Simple vs Otsu')\n",
    "axes[1,3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detección de bordes en escala de grises\n",
    "def detectar_bordes(imagen_gris):\n",
    "    \"\"\"Demuestra diferentes algoritmos de detección de bordes\"\"\"\n",
    "    # Suavizar imagen para reducir ruido\n",
    "    suavizada = cv2.GaussianBlur(imagen_gris, (5, 5), 0)\n",
    "    \n",
    "    # Algoritmos de detección de bordes\n",
    "    bordes_canny = cv2.Canny(suavizada, 50, 150)\n",
    "    \n",
    "    # Operadores Sobel\n",
    "    sobel_x = cv2.Sobel(suavizada, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(suavizada, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel_combined = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    sobel_combined = np.uint8(np.clip(sobel_combined, 0, 255))\n",
    "    \n",
    "    # Operador Laplaciano\n",
    "    laplaciano = cv2.Laplacian(suavizada, cv2.CV_64F)\n",
    "    laplaciano = np.uint8(np.clip(np.abs(laplaciano), 0, 255))\n",
    "    \n",
    "    return bordes_canny, sobel_combined, laplaciano\n",
    "\n",
    "# Convertir imagen de colores a escala de grises para detección de bordes\n",
    "gris_para_bordes = cv2.cvtColor(img_gradiente, cv2.COLOR_BGR2GRAY)\n",
    "canny, sobel, laplaciano = detectar_bordes(gris_para_bordes)\n",
    "\n",
    "# Visualizar detección de bordes\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(gris_para_bordes, cmap='gray')\n",
    "axes[0].set_title('Imagen en Escala de Grises')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(canny, cmap='gray')\n",
    "axes[1].set_title('Bordes Canny')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(sobel, cmap='gray')\n",
    "axes[2].set_title('Bordes Sobel')\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(laplaciano, cmap='gray')\n",
    "axes[3].set_title('Bordes Laplaciano')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a33fb",
   "metadata": {},
   "source": [
    "TODO: CREAR EL DE XYZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f1d94a",
   "metadata": {},
   "source": [
    "## 7. Comparación y Análisis Final\n",
    "\n",
    "### Resumen de Espacios de Color Analizados\n",
    "\n",
    "| Espacio | Canales | Principales Ventajas | Aplicaciones Típicas |\n",
    "|---------|---------|---------------------|---------------------|\n",
    "| **RGB** | R, G, B | Intuitivo, estándar dispositivos | Visualización, captura básica |\n",
    "| **HSV** | H, S, V | Robusto a iluminación, segmentación | Detección objetos, seguimiento |\n",
    "| **CIELAB** | L*, a*, b* | Uniforme perceptual, ΔE preciso | Control calidad, medicina |\n",
    "| **YCrCb** | Y, Cr, Cb | Separación luminancia, compresión | Detección piel, video |\n",
    "| **Escala Grises** | Intensidad | Rápido, simple, estructural | OCR, códigos barras, bordes |\n",
    "| **XYZ** | X, Y, Z | Estándar fundamental, calibración | Colorimetría, investigación |\n",
    "\n",
    "### Criterios de Selección\n",
    "\n",
    "#### Para Segmentación por Color:\n",
    "1. **HSV**: Primera opción para objetos de color conocido\n",
    "2. **LAB**: Cuando se requiere precisión perceptual\n",
    "3. **YCrCb**: Específicamente para detección de piel\n",
    "\n",
    "#### Para Análisis Estructural:\n",
    "1. **Escala de Grises**: Detección de formas, texturas, bordes\n",
    "2. **Canal Y (YCrCb)** o **L (LAB)**: Para conservar información de luminancia\n",
    "\n",
    "#### Para Aplicaciones Industriales:\n",
    "1. **LAB**: Control de calidad, matching de colores\n",
    "2. **XYZ**: Calibración de dispositivos, estándares\n",
    "\n",
    "#### Para Compresión/Transmisión:\n",
    "1. **YCrCb**: Base de JPEG, video codecs\n",
    "2. **Escala de Grises**: Máxima compresión"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
